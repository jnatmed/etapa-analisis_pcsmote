{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "RUTA_LOGS = \".\"\n",
    "RUTA_TEST = \".\"   # donde están los *_test.csv\n",
    "\n",
    "archivos_xlsx = [\n",
    "    f for f in glob.glob(os.path.join(RUTA_LOGS, \"*.xlsx\"))\n",
    "    if not os.path.basename(f).startswith(\"~$\")\n",
    "]\n",
    "\n",
    "archivos_test = glob.glob(os.path.join(RUTA_TEST, \"*_test.csv\"))\n",
    "\n",
    "# ---- cargar distribuciones de test ----\n",
    "dist_test = {}\n",
    "for ruta in archivos_test:\n",
    "    nombre = os.path.basename(ruta)\n",
    "    dataset = nombre.split(\"_tdataset\")[0]\n",
    "    df_test = pd.read_csv(ruta)\n",
    "    col_clase = df_test.columns[-1]\n",
    "    dist_test[dataset] = df_test[col_clase].value_counts()\n",
    "\n",
    "# ---- análisis principal ----\n",
    "for ruta in archivos_xlsx:\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    dataset = (\n",
    "        nombre_archivo\n",
    "        .replace(\"log_pcsmote_x_muestra_\", \"\")\n",
    "        .replace(\".xlsx\", \"\")\n",
    "    )\n",
    "\n",
    "    df = pd.read_excel(ruta, engine=\"openpyxl\")\n",
    "\n",
    "    columnas = {\n",
    "        \"configuracion\",\n",
    "        \"clase_objetivo\",\n",
    "        \"synthetics_from_this_seed\",\n",
    "        \"es_semilla_valida\"\n",
    "    }\n",
    "    if not columnas <= set(df.columns):\n",
    "        raise ValueError(f\"Columnas faltantes en {nombre_archivo}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    for configuracion, bloque in df.groupby(\"configuracion\"):\n",
    "\n",
    "        print(f\"\\n{configuracion}\")\n",
    "        print(\"-\" * len(configuracion))\n",
    "\n",
    "        resumen = (\n",
    "            bloque\n",
    "            .groupby(\"clase_objetivo\")\n",
    "            .agg(\n",
    "                SG=(\"synthetics_from_this_seed\", \"sum\"),\n",
    "                SV=(\"es_semilla_valida\", \"sum\")\n",
    "            )\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        # imprimir por clase\n",
    "        for clase, fila in resumen.iterrows():\n",
    "            sg = int(fila[\"SG\"])\n",
    "            sv = int(fila[\"SV\"])\n",
    "            ratio = sg / sv if sv > 0 else 0\n",
    "            print(f\"{clase:<6} SV={sv:<3} SG={sg:<4} SG/SV={ratio:.2f}\")\n",
    "\n",
    "        # métricas globales\n",
    "        total_sg = resumen[\"SG\"].sum()\n",
    "        cobertura = (resumen[\"SG\"] > 0).sum()\n",
    "        total_clases = len(resumen)\n",
    "\n",
    "        print(f\"\\n  ▶ Total sintéticos (SG): {int(total_sg)}\")\n",
    "        print(f\"  ▶ Cobertura de clases  : {cobertura}/{total_clases}\")\n",
    "\n",
    "        if total_sg == 0:\n",
    "            print(\"  ⚠ Configuración inválida (SG = 0)\")\n",
    "            continue\n",
    "\n",
    "        # ---- desalineación con test ----\n",
    "        if dataset in dist_test:\n",
    "            print(\"  ▶ Desalineación SG vs TEST:\")\n",
    "            for clase in resumen.index:\n",
    "                sg = resumen.loc[clase, \"SG\"]\n",
    "                ft = dist_test[dataset].get(clase, 0)\n",
    "                delta = sg - ft\n",
    "                print(f\"     {clase:<6} SG={sg:<4} TEST={ft:<3} Δ={delta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _slug(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Convierte texto a nombre de archivo seguro y estable.\n",
    "    \"\"\"\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = re.sub(r\"\\s+\", \"_\", texto)\n",
    "    texto = re.sub(r\"[^a-z0-9_\\-\\.]+\", \"\", texto)\n",
    "    return texto[:180] if len(texto) > 180 else texto\n",
    "\n",
    "\n",
    "def graficar_sg_sv_por_clase(\n",
    "    resumen: pd.DataFrame,\n",
    "    dataset: str,\n",
    "    configuracion: str,\n",
    "    directorio_graficos: str = \"graficos\",\n",
    "    mostrar_en_notebook: bool = True,\n",
    "    guardar: bool = True,\n",
    "    dpi: int = 140,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Genera:\n",
    "      1) Burbuja SV vs SG (tamaño ~ SG/SV)\n",
    "      2) Barra SG/SV por clase\n",
    "\n",
    "    Guarda en /graficos con nombres determinísticos por dataset+config,\n",
    "    por lo que se SOBREESCRIBEN al re-ejecutar.\n",
    "\n",
    "    Espera 'resumen' con índice=clase_objetivo y columnas: SG, SV.\n",
    "    \"\"\"\n",
    "\n",
    "    if resumen is None or len(resumen) == 0:\n",
    "        print(\"  ▶ Gráficos: resumen vacío (omitido)\")\n",
    "        return\n",
    "\n",
    "    if \"SG\" not in resumen.columns or \"SV\" not in resumen.columns:\n",
    "        print(\"  ▶ Gráficos: faltan columnas SG/SV en resumen (omitido)\")\n",
    "        return\n",
    "\n",
    "    # -------------------------\n",
    "    # Preparación de datos\n",
    "    # -------------------------\n",
    "    clases = []\n",
    "    lista_sv = []\n",
    "    lista_sg = []\n",
    "    lista_ratio = []\n",
    "\n",
    "    for clase, fila in resumen.iterrows():\n",
    "        sg = float(fila[\"SG\"]) if pd.notna(fila[\"SG\"]) else 0.0\n",
    "        sv = float(fila[\"SV\"]) if pd.notna(fila[\"SV\"]) else 0.0\n",
    "        ratio = (sg / sv) if sv > 0 else 0.0\n",
    "\n",
    "        clases.append(str(clase))\n",
    "        lista_sv.append(sv)\n",
    "        lista_sg.append(sg)\n",
    "        lista_ratio.append(ratio)\n",
    "\n",
    "    # Escala de tamaño (área en puntos^2)\n",
    "    max_ratio = max(lista_ratio) if len(lista_ratio) > 0 else 0.0\n",
    "    tamanios = []\n",
    "    for r in lista_ratio:\n",
    "        if max_ratio > 0:\n",
    "            tamanio = 80.0 + (r / max_ratio) * 1320.0\n",
    "        else:\n",
    "            tamanio = 80.0\n",
    "        tamanios.append(tamanio)\n",
    "\n",
    "    # -------------------------\n",
    "    # Rutas determinísticas\n",
    "    # -------------------------\n",
    "    base = f\"{_slug(dataset)}__{_slug(configuracion)}\"\n",
    "    out_dir = Path(directorio_graficos)\n",
    "    if guardar:\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ruta_burbuja = out_dir / f\"{base}__burbuja_sv_vs_sg.png\"\n",
    "    ruta_barra   = out_dir / f\"{base}__barra_sg_sv.png\"\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Burbuja (con leyenda)\n",
    "    # -------------------------\n",
    "    fig1 = plt.figure()\n",
    "\n",
    "    # puntos activos (SV>0 y SG>0)\n",
    "    for i in range(len(clases)):\n",
    "        if lista_sv[i] > 0 and lista_sg[i] > 0:\n",
    "            plt.scatter(\n",
    "                [lista_sv[i]],\n",
    "                [lista_sg[i]],\n",
    "                s=[tamanios[i]],\n",
    "                alpha=0.7,\n",
    "                label=clases[i]\n",
    "            )\n",
    "\n",
    "    # clases sin generación (no se grafican como puntos)\n",
    "    clases_inactivas = []\n",
    "    for i in range(len(clases)):\n",
    "        if not (lista_sv[i] > 0 and lista_sg[i] > 0):\n",
    "            clases_inactivas.append(clases[i])\n",
    "\n",
    "    plt.title(f\"{dataset} | {configuracion} | Burbuja SV vs SG (tamaño ~ SG/SV)\")\n",
    "    plt.xlabel(\"SV (semillas válidas)\")\n",
    "    plt.ylabel(\"SG (sintéticos generados)\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # leyenda fuera del gráfico\n",
    "    plt.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 1.0),\n",
    "        borderaxespad=0.0,\n",
    "        fontsize=9,\n",
    "        title=\"Clase\"\n",
    "    )\n",
    "\n",
    "    # nota para clases inactivas\n",
    "    if len(clases_inactivas) > 0:\n",
    "        texto = \"Sin generación (SV=0 o SG=0): \" + \", \".join(clases_inactivas)\n",
    "        plt.figtext(0.01, 0.01, texto, ha=\"left\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    # un poco de aire para que no quede pegado al borde\n",
    "    plt.margins(x=0.12, y=0.15)\n",
    "\n",
    "    if guardar:\n",
    "        fig1.savefig(ruta_burbuja, dpi=dpi, bbox_inches=\"tight\")  # sobreescribe\n",
    "\n",
    "    if mostrar_en_notebook:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig1)\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Barra SG/SV\n",
    "    # -------------------------\n",
    "    # Orden descendente para lectura\n",
    "    indices_ordenados = list(range(len(clases)))\n",
    "    indices_ordenados.sort(key=lambda i: lista_ratio[i], reverse=True)\n",
    "\n",
    "    clases_ord = []\n",
    "    ratio_ord = []\n",
    "    for i in indices_ordenados:\n",
    "        clases_ord.append(clases[i])\n",
    "        ratio_ord.append(lista_ratio[i])\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.bar(clases_ord, ratio_ord)\n",
    "\n",
    "    plt.title(f\"{dataset} | {configuracion} | Barra SG/SV por clase\")\n",
    "    plt.xlabel(\"Clase\")\n",
    "    plt.ylabel(\"SG/SV\")\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.grid(True, axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if guardar:\n",
    "        fig2.savefig(ruta_barra, dpi=dpi, bbox_inches=\"tight\")  # sobreescribe\n",
    "\n",
    "    if mostrar_en_notebook:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd9e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Dataset: predict_faults\n",
      "====================================================================================================\n",
      "\n",
      "PRD85_PR40_CPent_UD050_UR045_PE60_I0\n",
      "------------------------------------\n",
      "Heat Dissipation Failure SV=12  SG=7632 SG/SV=636.00\n",
      "Overstrain Failure SV=4   SG=7660 SG/SV=1915.00\n",
      "Power Failure SV=14  SG=7646 SG/SV=546.14\n",
      "Random Failures SV=0   SG=0    SG/SV=0.00\n",
      "Tool Wear Failure SV=0   SG=0    SG/SV=0.00\n",
      "\n",
      "  ▶ Total sintéticos (SG): 22938\n",
      "  ▶ Cobertura de clases  : 3/5\n",
      "  ▶ Entropía (solo SV=1):\n",
      "     n=30 | media=0.6863 | std=0.2648 | CV=0.3859\n",
      "  ▶ Correlación (Spearman) entropía ↔ SG_por_semilla (solo SV=1):\n",
      "     rho=0.6154\n",
      "  ▶ Eficiencia de semillas (solo SV=1):\n",
      "     SV_totales=30 | SV_activas=30 (100.00%)\n",
      "     SG_por_semilla_activa: media=764.600 | mediana=610.000\n",
      "  ▶ Diferencias SV=1 vs SV=0 (media y std):\n",
      "     entropia SV=1 media=0.6863 std=0.2648 | SV=0 media=0.5984 std=0.4030\n",
      "     densidad SV=1 media=0.9429 std=0.1100 | SV=0 media=0.8381 std=0.3021\n",
      "     riesgo   SV=1 media=0.0810 std=0.0970 | SV=0 media=0.2903 std=0.3025\n",
      "  ▶ Análisis de frontera por criterio:\n",
      "     pureza   [entropia] | pasa: n=41   μ=0.6586 σ=0.2790 | no pasa: n=237  μ=0.5992 σ=0.4071 | Δμ=0.0594\n",
      "     densidad [densidad] | pasa: n=236  μ=0.9607 σ=0.1075 | no pasa: n=42   μ=0.2245 σ=0.1674 | Δμ=0.7362\n",
      "     riesgo   [riesgo] | pasa: n=214  μ=0.1288 σ=0.1475 | no pasa: n=64   μ=0.7321 σ=0.1538 | Δμ=-0.6033\n",
      "\n",
      "PRD85_PR40_CPent_UD050_UR045_PE60_I1\n",
      "------------------------------------\n",
      "Heat Dissipation Failure SV=12  SG=7555 SG/SV=629.58\n",
      "Overstrain Failure SV=4   SG=7583 SG/SV=1895.75\n",
      "Power Failure SV=15  SG=7569 SG/SV=504.60\n",
      "Random Failures SV=0   SG=0    SG/SV=0.00\n",
      "Tool Wear Failure SV=0   SG=0    SG/SV=0.00\n",
      "\n",
      "  ▶ Total sintéticos (SG): 22707\n",
      "  ▶ Cobertura de clases  : 3/5\n",
      "  ▶ Entropía (solo SV=1):\n",
      "     n=31 | media=0.4471 | std=0.4197 | CV=0.9388\n",
      "  ▶ Correlación (Spearman) entropía ↔ SG_por_semilla (solo SV=1):\n",
      "     rho=0.8274\n",
      "  ▶ Eficiencia de semillas (solo SV=1):\n",
      "     SV_totales=31 | SV_activas=31 (100.00%)\n",
      "     SG_por_semilla_activa: media=732.484 | mediana=593.000\n",
      "  ▶ Diferencias SV=1 vs SV=0 (media y std):\n",
      "     entropia SV=1 media=0.4471 std=0.4197 | SV=0 media=0.5942 std=0.4061\n",
      "     densidad SV=1 media=0.9217 std=0.1514 | SV=0 media=0.8400 std=0.2953\n",
      "     riesgo   SV=1 media=0.0553 std=0.0953 | SV=0 media=0.2928 std=0.3082\n",
      "  ▶ Análisis de frontera por criterio:\n",
      "     pureza   [entropia] | pasa: n=42   μ=0.3992 σ=0.4125 | no pasa: n=231  μ=0.6099 σ=0.4015 | Δμ=-0.2107\n",
      "     densidad [densidad] | pasa: n=230  μ=0.9602 σ=0.1110 | no pasa: n=43   μ=0.2558 σ=0.1607 | Δμ=0.7044\n",
      "     riesgo   [riesgo] | pasa: n=210  μ=0.1231 σ=0.1502 | no pasa: n=63   μ=0.7415 σ=0.1536 | Δμ=-0.6184\n",
      "\n",
      "PRD85_PR50_CPprop_UD050_UR055_Upp045_I0\n",
      "---------------------------------------\n",
      "Heat Dissipation Failure SV=22  SG=7632 SG/SV=346.91\n",
      "Overstrain Failure SV=12  SG=7660 SG/SV=638.33\n",
      "Power Failure SV=17  SG=7646 SG/SV=449.76\n",
      "Random Failures SV=0   SG=0    SG/SV=0.00\n",
      "Tool Wear Failure SV=0   SG=0    SG/SV=0.00\n",
      "\n",
      "  ▶ Total sintéticos (SG): 22938\n",
      "  ▶ Cobertura de clases  : 3/5\n",
      "  ▶ Entropía: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Correlación entropía↔SG: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Eficiencia de semillas (solo SV=1):\n",
      "     SV_totales=51 | SV_activas=51 (100.00%)\n",
      "     SG_por_semilla_activa: media=449.765 | mediana=439.000\n",
      "  ▶ Diferencias SV=1 vs SV=0 (media y std):\n",
      "     entropia (omitido: NaN tras conversión)\n",
      "     densidad SV=1 media=0.9664 std=0.0885 | SV=0 media=0.8232 std=0.3116\n",
      "     riesgo   SV=1 media=0.1737 std=0.1599 | SV=0 media=0.3782 std=0.3476\n",
      "  ▶ Análisis de frontera por criterio:\n",
      "     pureza   [proporcion_min_valor] | pasa: n=67   μ=0.7122 σ=0.1373 | no pasa: n=211  μ=0.1936 σ=0.1639 | Δμ=0.5185\n",
      "     densidad [densidad] | pasa: n=236  μ=0.9607 σ=0.1075 | no pasa: n=42   μ=0.2245 σ=0.1674 | Δμ=0.7362\n",
      "     riesgo   [riesgo] | pasa: n=191  μ=0.1444 σ=0.1530 | no pasa: n=87   μ=0.7718 σ=0.1651 | Δμ=-0.6274\n",
      "\n",
      "PRD85_PR50_CPprop_UD050_UR055_Upp045_I1\n",
      "---------------------------------------\n",
      "Heat Dissipation Failure SV=22  SG=7555 SG/SV=343.41\n",
      "Overstrain Failure SV=12  SG=7583 SG/SV=631.92\n",
      "Power Failure SV=20  SG=7569 SG/SV=378.45\n",
      "Random Failures SV=0   SG=0    SG/SV=0.00\n",
      "Tool Wear Failure SV=0   SG=0    SG/SV=0.00\n",
      "\n",
      "  ▶ Total sintéticos (SG): 22707\n",
      "  ▶ Cobertura de clases  : 3/5\n",
      "  ▶ Entropía: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Correlación entropía↔SG: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Eficiencia de semillas (solo SV=1):\n",
      "     SV_totales=54 | SV_activas=54 (100.00%)\n",
      "     SG_por_semilla_activa: media=420.500 | mediana=372.000\n",
      "  ▶ Diferencias SV=1 vs SV=0 (media y std):\n",
      "     entropia (omitido: NaN tras conversión)\n",
      "     densidad SV=1 media=0.9471 std=0.1310 | SV=0 media=0.8252 std=0.3054\n",
      "     riesgo   SV=1 media=0.1508 std=0.1675 | SV=0 media=0.3829 std=0.3496\n",
      "  ▶ Análisis de frontera por criterio:\n",
      "     pureza   [proporcion_min_valor] | pasa: n=70   μ=0.7551 σ=0.1806 | no pasa: n=203  μ=0.1949 σ=0.1618 | Δμ=0.5602\n",
      "     densidad [densidad] | pasa: n=230  μ=0.9602 σ=0.1110 | no pasa: n=43   μ=0.2558 σ=0.1607 | Δμ=0.7044\n",
      "     riesgo   [riesgo] | pasa: n=185  μ=0.1328 σ=0.1526 | no pasa: n=88   μ=0.7662 σ=0.1609 | Δμ=-0.6334\n",
      "\n",
      "PRD85_PR50_CPprop_UD050_UR055_Upp045_I3\n",
      "---------------------------------------\n",
      "Heat Dissipation Failure SV=22  SG=7403 SG/SV=336.50\n",
      "Overstrain Failure SV=12  SG=7430 SG/SV=619.17\n",
      "Power Failure SV=21  SG=7417 SG/SV=353.19\n",
      "Random Failures SV=0   SG=0    SG/SV=0.00\n",
      "Tool Wear Failure SV=0   SG=0    SG/SV=0.00\n",
      "\n",
      "  ▶ Total sintéticos (SG): 22250\n",
      "  ▶ Cobertura de clases  : 3/5\n",
      "  ▶ Entropía: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Correlación entropía↔SG: no aplica (criterio_pureza=proporcion)\n",
      "  ▶ Eficiencia de semillas (solo SV=1):\n",
      "     SV_totales=55 | SV_activas=55 (100.00%)\n",
      "     SG_por_semilla_activa: media=404.545 | mediana=353.000\n",
      "  ▶ Diferencias SV=1 vs SV=0 (media y std):\n",
      "     entropia (omitido: NaN tras conversión)\n",
      "     densidad SV=1 media=0.9455 std=0.1275 | SV=0 media=0.8241 std=0.3059\n",
      "     riesgo   SV=1 media=0.1455 std=0.1683 | SV=0 media=0.3848 std=0.3462\n",
      "  ▶ Análisis de frontera por criterio:\n",
      "     pureza   [proporcion_min_valor] | pasa: n=71   μ=0.7586 σ=0.1848 | no pasa: n=196  μ=0.1975 σ=0.1619 | Δμ=0.5610\n",
      "     densidad [densidad] | pasa: n=226  μ=0.9583 σ=0.1122 | no pasa: n=41   μ=0.2474 σ=0.1499 | Δμ=0.7109\n",
      "     riesgo   [riesgo] | pasa: n=180  μ=0.1317 σ=0.1528 | no pasa: n=87   μ=0.7570 σ=0.1603 | Δμ=-0.6252\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# DATASETS A GRAFICAR\n",
    "# =========================\n",
    "datasets_a_graficar = {\n",
    "    \"predict_faults\",\n",
    "    # \"heart\",\n",
    "    # \"wdbc\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def tiene_columnas(df: pd.DataFrame, columnas: list) -> bool:\n",
    "    for c in columnas:\n",
    "        if c not in df.columns:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def validar_columnas_obligatorias(df: pd.DataFrame, nombre_archivo: str) -> None:\n",
    "    columnas_obligatorias = [\n",
    "        \"configuracion\",\n",
    "        \"clase_objetivo\",\n",
    "        \"synthetics_from_this_seed\",\n",
    "        \"es_semilla_valida\",\n",
    "    ]\n",
    "\n",
    "    faltantes = []\n",
    "    for c in columnas_obligatorias:\n",
    "        if c not in df.columns:\n",
    "            faltantes.append(c)\n",
    "\n",
    "    if len(faltantes) > 0:\n",
    "        raise ValueError(f\"Columnas faltantes en {nombre_archivo}: {faltantes}\")\n",
    "\n",
    "\n",
    "def convertir_a_float_seguro(serie: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convierte una serie a float de forma robusta:\n",
    "    - numéricos -> float\n",
    "    - strings \"7/7\" -> 1.0\n",
    "    - strings con coma decimal -> reemplaza coma por punto\n",
    "    - cualquier otra cosa no convertible -> NaN\n",
    "    \"\"\"\n",
    "    # Paso 1: forzamos a string para procesar patrones, pero preservamos NaN\n",
    "    s = serie.copy()\n",
    "\n",
    "    # Normalizamos a string sin perder NaN\n",
    "    s = s.astype(\"object\")\n",
    "\n",
    "    valores_convertidos = []\n",
    "\n",
    "    for v in s.values:\n",
    "        if pd.isna(v):\n",
    "            valores_convertidos.append(float(\"nan\"))\n",
    "            continue\n",
    "\n",
    "        # Si ya es numérico\n",
    "        if isinstance(v, (int, float)):\n",
    "            valores_convertidos.append(float(v))\n",
    "            continue\n",
    "\n",
    "        texto = str(v).strip()\n",
    "\n",
    "        if texto == \"\":\n",
    "            valores_convertidos.append(float(\"nan\"))\n",
    "            continue\n",
    "\n",
    "        # Caso \"a/b\"\n",
    "        if \"/\" in texto:\n",
    "            partes = texto.split(\"/\")\n",
    "            if len(partes) == 2:\n",
    "                a_txt = partes[0].strip()\n",
    "                b_txt = partes[1].strip()\n",
    "                try:\n",
    "                    a = float(a_txt.replace(\",\", \".\"))\n",
    "                    b = float(b_txt.replace(\",\", \".\"))\n",
    "                    if b != 0:\n",
    "                        valores_convertidos.append(a / b)\n",
    "                    else:\n",
    "                        valores_convertidos.append(float(\"nan\"))\n",
    "                except Exception:\n",
    "                    valores_convertidos.append(float(\"nan\"))\n",
    "                continue\n",
    "\n",
    "        # Caso decimal con coma\n",
    "        texto = texto.replace(\",\", \".\")\n",
    "\n",
    "        try:\n",
    "            valores_convertidos.append(float(texto))\n",
    "        except Exception:\n",
    "            valores_convertidos.append(float(\"nan\"))\n",
    "\n",
    "    return pd.Series(valores_convertidos, index=serie.index)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CARGA DISTRIBUCIONES TEST\n",
    "# =========================\n",
    "def cargar_distribuciones_test(ruta_test: str) -> dict:\n",
    "    archivos_test = glob.glob(os.path.join(ruta_test, \"*_test.csv\"))\n",
    "    dist_test = {}\n",
    "\n",
    "    for ruta in archivos_test:\n",
    "        nombre = os.path.basename(ruta)\n",
    "        dataset = nombre.split(\"_tdataset\")[0]\n",
    "\n",
    "        df_test = pd.read_csv(ruta)\n",
    "        col_clase = df_test.columns[-1]\n",
    "        dist_test[dataset] = df_test[col_clase].value_counts()\n",
    "\n",
    "    return dist_test\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 1: SG/SV POR CLASE\n",
    "# =========================\n",
    "def construir_resumen_sg_sv_por_clase(bloque: pd.DataFrame) -> pd.DataFrame:\n",
    "    resumen = (\n",
    "        bloque\n",
    "        .groupby(\"clase_objetivo\")\n",
    "        .agg(\n",
    "            SG=(\"synthetics_from_this_seed\", \"sum\"),\n",
    "            SV=(\"es_semilla_valida\", \"sum\"),\n",
    "        )\n",
    "        .sort_index()\n",
    "    )\n",
    "    return resumen\n",
    "\n",
    "\n",
    "def imprimir_resumen_sg_sv(resumen: pd.DataFrame) -> int:\n",
    "    for clase, fila in resumen.iterrows():\n",
    "        sg = int(fila[\"SG\"])\n",
    "        sv = int(fila[\"SV\"])\n",
    "        ratio = sg / sv if sv > 0 else 0\n",
    "        print(f\"{clase:<6} SV={sv:<3} SG={sg:<4} SG/SV={ratio:.2f}\")\n",
    "\n",
    "    total_sg = int(resumen[\"SG\"].sum())\n",
    "    cobertura = int((resumen[\"SG\"] > 0).sum())\n",
    "    total_clases = int(len(resumen))\n",
    "\n",
    "    print(f\"\\n  ▶ Total sintéticos (SG): {total_sg}\")\n",
    "    print(f\"  ▶ Cobertura de clases  : {cobertura}/{total_clases}\")\n",
    "\n",
    "    if total_sg == 0:\n",
    "        print(\"  ⚠ Configuración inválida (SG = 0)\")\n",
    "\n",
    "    return total_sg\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 2: DESALINEACIÓN VS TEST\n",
    "# =========================\n",
    "def imprimir_desalineacion_vs_test(dataset: str, resumen: pd.DataFrame, dist_test: dict) -> None:\n",
    "    if dataset not in dist_test:\n",
    "        return\n",
    "\n",
    "    print(\"  ▶ Desalineación SG vs TEST:\")\n",
    "    for clase in resumen.index:\n",
    "        sg = int(resumen.loc[clase, \"SG\"])\n",
    "        ft = int(dist_test[dataset].get(clase, 0))\n",
    "        delta = sg - ft\n",
    "        print(f\"     {clase:<6} SG={sg:<4} TEST={ft:<3} Δ={delta}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 3: ENTROPÍA (media/std/CV) EN SV=1\n",
    "# =========================\n",
    "def analizar_entropia_en_semillas_validas(bloque: pd.DataFrame) -> None:\n",
    "    # Si el criterio de pureza es \"proporcion\", entropía NO aplica\n",
    "    if \"criterio_pureza\" in bloque.columns:\n",
    "        criterio = str(bloque[\"criterio_pureza\"].iloc[0]).strip().lower()\n",
    "        if \"prop\" in criterio:\n",
    "            print(\"  ▶ Entropía: no aplica (criterio_pureza=proporcion)\")\n",
    "            return\n",
    "\n",
    "    if not tiene_columnas(bloque, [\"entropia\", \"es_semilla_valida\"]):\n",
    "        print(\"  ▶ Entropía: (omitido, faltan columnas)\")\n",
    "        return\n",
    "\n",
    "    semillas_validas = bloque[bloque[\"es_semilla_valida\"] == 1]\n",
    "    if len(semillas_validas) == 0:\n",
    "        print(\"  ▶ Entropía: sin semillas válidas\")\n",
    "        return\n",
    "\n",
    "    ent = convertir_a_float_seguro(semillas_validas[\"entropia\"])\n",
    "    ent = ent.dropna()\n",
    "\n",
    "    if len(ent) == 0:\n",
    "        print(\"  ▶ Entropía: todos NaN tras conversión\")\n",
    "        return\n",
    "\n",
    "    media = float(ent.mean())\n",
    "    std = float(ent.std(ddof=1)) if len(ent) > 1 else 0.0\n",
    "    cv = (std / media) if media != 0 else 0.0\n",
    "\n",
    "    print(\"  ▶ Entropía (solo SV=1):\")\n",
    "    print(f\"     n={len(ent)} | media={media:.4f} | std={std:.4f} | CV={cv:.4f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 4: CORRELACIÓN entropía ↔ SG_por_semilla (Spearman) EN SV=1\n",
    "# =========================\n",
    "def analizar_correlacion_entropia_vs_sg(bloque: pd.DataFrame) -> None:\n",
    "\n",
    "    # Si el criterio de pureza es \"proporcion\", entropía NO aplica\n",
    "    if \"criterio_pureza\" in bloque.columns:\n",
    "        criterio = str(bloque[\"criterio_pureza\"].iloc[0]).strip().lower()\n",
    "        if \"prop\" in criterio:\n",
    "            print(\"  ▶ Correlación entropía↔SG: no aplica (criterio_pureza=proporcion)\")\n",
    "            return\n",
    "\n",
    "    cols = [\"entropia\", \"synthetics_from_this_seed\", \"es_semilla_valida\"]\n",
    "    if not tiene_columnas(bloque, cols):\n",
    "        print(\"  ▶ Correlación entropía↔SG: (omitido, faltan columnas)\")\n",
    "        return\n",
    "\n",
    "    semillas_validas = bloque[bloque[\"es_semilla_valida\"] == 1].copy()\n",
    "    if len(semillas_validas) < 3:\n",
    "        print(\"  ▶ Correlación entropía↔SG: datos insuficientes (n<3)\")\n",
    "        return\n",
    "\n",
    "    x = convertir_a_float_seguro(semillas_validas[\"entropia\"])\n",
    "    y = convertir_a_float_seguro(semillas_validas[\"synthetics_from_this_seed\"])\n",
    "\n",
    "    # Alineamos y tiramos NaN\n",
    "    tmp = pd.DataFrame({\"x\": x, \"y\": y}).dropna()\n",
    "    if len(tmp) < 3:\n",
    "        print(\"  ▶ Correlación entropía↔SG: datos insuficientes tras limpieza\")\n",
    "        return\n",
    "\n",
    "    corr = tmp[\"x\"].corr(tmp[\"y\"], method=\"spearman\")\n",
    "    if pd.isna(corr):\n",
    "        print(\"  ▶ Correlación entropía↔SG: no calculable\")\n",
    "        return\n",
    "\n",
    "    print(\"  ▶ Correlación (Spearman) entropía ↔ SG_por_semilla (solo SV=1):\")\n",
    "    print(f\"     rho={float(corr):.4f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 5: EFICIENCIA DE SEMILLAS (SV activas)\n",
    "# =========================\n",
    "def analizar_eficiencia_de_semillas(bloque: pd.DataFrame) -> None:\n",
    "    cols = [\"es_semilla_valida\", \"synthetics_from_this_seed\"]\n",
    "    if not tiene_columnas(bloque, cols):\n",
    "        print(\"  ▶ Eficiencia semillas: (omitido, faltan columnas)\")\n",
    "        return\n",
    "\n",
    "    semillas_validas = bloque[bloque[\"es_semilla_valida\"] == 1].copy()\n",
    "    if len(semillas_validas) == 0:\n",
    "        print(\"  ▶ Eficiencia semillas: sin semillas válidas\")\n",
    "        return\n",
    "\n",
    "    total_sv = int(len(semillas_validas))\n",
    "\n",
    "    sg_por_semilla = convertir_a_float_seguro(semillas_validas[\"synthetics_from_this_seed\"])\n",
    "    semillas_validas = semillas_validas.copy()\n",
    "    semillas_validas[\"sg_float\"] = sg_por_semilla\n",
    "\n",
    "    activas = semillas_validas[semillas_validas[\"sg_float\"] > 0]\n",
    "    cant_activas = int(len(activas))\n",
    "    pct_activas = (cant_activas / total_sv) if total_sv > 0 else 0.0\n",
    "\n",
    "    if cant_activas > 0:\n",
    "        media_sg_activas = float(activas[\"sg_float\"].mean())\n",
    "        mediana_sg_activas = float(activas[\"sg_float\"].median())\n",
    "    else:\n",
    "        media_sg_activas = 0.0\n",
    "        mediana_sg_activas = 0.0\n",
    "\n",
    "    print(\"  ▶ Eficiencia de semillas (solo SV=1):\")\n",
    "    print(f\"     SV_totales={total_sv} | SV_activas={cant_activas} ({pct_activas*100:.2f}%)\")\n",
    "    print(f\"     SG_por_semilla_activa: media={media_sg_activas:.3f} | mediana={mediana_sg_activas:.3f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 6: SV=1 vs SV=0 (entropia/densidad/riesgo)\n",
    "# =========================\n",
    "def analizar_diferencias_sv_vs_no_sv(bloque: pd.DataFrame) -> None:\n",
    "    if \"es_semilla_valida\" not in bloque.columns:\n",
    "        print(\"  ▶ Comparación SV vs no-SV: (omitido, falta es_semilla_valida)\")\n",
    "        return\n",
    "\n",
    "    columnas = []\n",
    "    for c in [\"entropia\", \"densidad\", \"riesgo\"]:\n",
    "        if c in bloque.columns:\n",
    "            columnas.append(c)\n",
    "\n",
    "    if len(columnas) == 0:\n",
    "        print(\"  ▶ Comparación SV vs no-SV: (omitido, faltan entropia/densidad/riesgo)\")\n",
    "        return\n",
    "\n",
    "    sv = bloque[bloque[\"es_semilla_valida\"] == 1]\n",
    "    no_sv = bloque[bloque[\"es_semilla_valida\"] == 0]\n",
    "\n",
    "    if len(sv) == 0 or len(no_sv) == 0:\n",
    "        print(\"  ▶ Comparación SV vs no-SV: datos insuficientes (uno de los grupos vacío)\")\n",
    "        return\n",
    "\n",
    "    print(\"  ▶ Diferencias SV=1 vs SV=0 (media y std):\")\n",
    "    for c in columnas:\n",
    "        v1 = convertir_a_float_seguro(sv[c]).dropna()\n",
    "        v0 = convertir_a_float_seguro(no_sv[c]).dropna()\n",
    "\n",
    "        if len(v1) == 0 or len(v0) == 0:\n",
    "            print(f\"     {c:<8} (omitido: NaN tras conversión)\")\n",
    "            continue\n",
    "\n",
    "        media_1 = float(v1.mean())\n",
    "        std_1 = float(v1.std(ddof=1)) if len(v1) > 1 else 0.0\n",
    "\n",
    "        media_0 = float(v0.mean())\n",
    "        std_0 = float(v0.std(ddof=1)) if len(v0) > 1 else 0.0\n",
    "\n",
    "        print(f\"     {c:<8} SV=1 media={media_1:.4f} std={std_1:.4f} | SV=0 media={media_0:.4f} std={std_0:.4f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANÁLISIS 7: FRONTERA “REAL” vs SEMILLAS MUERTAS (por criterio interno)\n",
    "# =========================\n",
    "def analizar_frontera_por_criterio(bloque: pd.DataFrame) -> None:\n",
    "    # -------------------------\n",
    "    # 1) Validación base\n",
    "    # -------------------------\n",
    "    columnas_base = [\n",
    "        \"pasa_pureza\", \"pasa_densidad\", \"pasa_riesgo\",\n",
    "        \"densidad\", \"riesgo\"\n",
    "    ]\n",
    "\n",
    "    for col in columnas_base:\n",
    "        if col not in bloque.columns:\n",
    "            print(\"  ▶ Frontera por criterio: (omitido, faltan columnas)\")\n",
    "            return\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Elegir variable para pureza según criterio_pureza\n",
    "    # -------------------------\n",
    "    col_valor_pureza = \"entropia\"  # default\n",
    "\n",
    "    if \"criterio_pureza\" in bloque.columns:\n",
    "        criterio = str(bloque[\"criterio_pureza\"].iloc[0]).strip().lower()\n",
    "\n",
    "        # Ajustá esta condición si tu campo tiene otros nombres\n",
    "        if \"prop\" in criterio:\n",
    "            col_valor_pureza = \"proporcion_min_valor\"\n",
    "        else:\n",
    "            col_valor_pureza = \"entropia\"\n",
    "\n",
    "    # Validación específica de la columna de pureza elegida\n",
    "    if col_valor_pureza not in bloque.columns:\n",
    "        print(f\"  ▶ Frontera por criterio: (omitido, falta {col_valor_pureza})\")\n",
    "        return\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Definir criterios a analizar\n",
    "    # -------------------------\n",
    "    criterios = [\n",
    "        {\"nombre\": \"pureza\",   \"col_pasa\": \"pasa_pureza\",   \"col_valor\": col_valor_pureza},\n",
    "        {\"nombre\": \"densidad\", \"col_pasa\": \"pasa_densidad\", \"col_valor\": \"densidad\"},\n",
    "        {\"nombre\": \"riesgo\",   \"col_pasa\": \"pasa_riesgo\",   \"col_valor\": \"riesgo\"},\n",
    "    ]\n",
    "\n",
    "    print(\"  ▶ Análisis de frontera por criterio:\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Ejecutar análisis: pasa vs no_pasa\n",
    "    # -------------------------\n",
    "    for crit in criterios:\n",
    "        nombre = crit[\"nombre\"]\n",
    "        col_pasa = crit[\"col_pasa\"]\n",
    "        col_valor = crit[\"col_valor\"]\n",
    "\n",
    "        pasa = bloque[bloque[col_pasa] == 1][col_valor]\n",
    "        no_pasa = bloque[bloque[col_pasa] == 0][col_valor]\n",
    "\n",
    "        pasa_num = convertir_a_float_seguro(pasa).dropna()\n",
    "        no_num = convertir_a_float_seguro(no_pasa).dropna()\n",
    "\n",
    "        if len(pasa_num) == 0 or len(no_num) == 0:\n",
    "            print(f\"     {nombre:<8}: datos insuficientes (NaN tras conversión)\")\n",
    "            continue\n",
    "\n",
    "        media_pasa = float(pasa_num.mean())\n",
    "        std_pasa = float(pasa_num.std(ddof=1)) if len(pasa_num) > 1 else 0.0\n",
    "\n",
    "        media_no = float(no_num.mean())\n",
    "        std_no = float(no_num.std(ddof=1)) if len(no_num) > 1 else 0.0\n",
    "\n",
    "        delta_media = media_pasa - media_no\n",
    "\n",
    "        etiqueta_valor = col_valor\n",
    "        print(\n",
    "            f\"     {nombre:<8} [{etiqueta_valor}] | \"\n",
    "            f\"pasa: n={len(pasa_num):<4} μ={media_pasa:.4f} σ={std_pasa:.4f} | \"\n",
    "            f\"no pasa: n={len(no_num):<4} μ={media_no:.4f} σ={std_no:.4f} | \"\n",
    "            f\"Δμ={delta_media:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# =========================\n",
    "RUTA_LOGS = \".\"\n",
    "RUTA_TEST = \".\"\n",
    "\n",
    "archivos_xlsx = [\n",
    "    f for f in glob.glob(os.path.join(RUTA_LOGS, \"*.xlsx\"))\n",
    "    if not os.path.basename(f).startswith(\"~$\")\n",
    "]\n",
    "\n",
    "dist_test = cargar_distribuciones_test(RUTA_TEST)\n",
    "\n",
    "for ruta in archivos_xlsx:\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    dataset = (\n",
    "        nombre_archivo\n",
    "        .replace(\"log_pcsmote_x_muestra_\", \"\")\n",
    "        .replace(\".xlsx\", \"\")\n",
    "    )\n",
    "\n",
    "    df = pd.read_excel(ruta, engine=\"openpyxl\")\n",
    "    validar_columnas_obligatorias(df, nombre_archivo)\n",
    "\n",
    "    if dataset in datasets_a_graficar:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "    for configuracion, bloque in df.groupby(\"configuracion\"):\n",
    "\n",
    "        if dataset not in datasets_a_graficar:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{configuracion}\")\n",
    "        print(\"-\" * len(configuracion))\n",
    "\n",
    "        # 1) Resumen SG/SV por clase\n",
    "        resumen = construir_resumen_sg_sv_por_clase(bloque)\n",
    "        total_sg = imprimir_resumen_sg_sv(resumen)\n",
    "\n",
    "        # 2) Desalineación vs TEST\n",
    "        if total_sg > 0:\n",
    "            imprimir_desalineacion_vs_test(dataset, resumen, dist_test)\n",
    "            titulo = f\"{dataset} | {configuracion}\"\n",
    "            \n",
    "            graficar_sg_sv_por_clase(\n",
    "                resumen=resumen,\n",
    "                dataset=dataset,\n",
    "                configuracion=configuracion,\n",
    "                directorio_graficos=\"graficos\",\n",
    "                mostrar_en_notebook=False,\n",
    "                guardar=True\n",
    "            )\n",
    "\n",
    "        # 3) Entropía (dispersión) en semillas válidas\n",
    "        analizar_entropia_en_semillas_validas(bloque)\n",
    "\n",
    "        # 4) Correlación entropía vs SG_por_semilla\n",
    "        analizar_correlacion_entropia_vs_sg(bloque)\n",
    "\n",
    "        # 5) Eficiencia de semillas\n",
    "        analizar_eficiencia_de_semillas(bloque)\n",
    "\n",
    "        # 6) SV=1 vs SV=0\n",
    "        analizar_diferencias_sv_vs_no_sv(bloque)\n",
    "\n",
    "        # 7) Frontera por criterio (pasa_* vs no pasa_*)\n",
    "        analizar_frontera_por_criterio(bloque)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
