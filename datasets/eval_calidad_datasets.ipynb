{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16440c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Importaciones listas.\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# üß© Celda 1 ‚Äî Importaciones\n",
    "# ================================================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import skew, normaltest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "sys.path.append(\"../datasets\")\n",
    "\n",
    "# --- M√≥dulos propios del proyecto ---\n",
    "from cargar_dataset import cargar_dataset                      # Funci√≥n para cargar datasets seg√∫n configuraci√≥n\n",
    "from config_datasets import config_datasets  \n",
    "print(\"‚úÖ Importaciones listas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553edd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Integraci√≥n: listo para usar cargar_dataset(config_datasets).\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# üß© Celda 2 ‚Äî Integraci√≥n con tu pipeline\n",
    "# ================================================\n",
    "# Requiere:\n",
    "# - config_datasets: dict con la configuraci√≥n de cada dataset (paths, columnas, etc.)\n",
    "# - cargar_dataset: funci√≥n existente en tu proyecto que retorna (X, y, info_adicional)\n",
    "\n",
    "# Si ten√©s m√≥dulos locales, descoment√° y ajust√°:\n",
    "# from config_datasets import config_datasets\n",
    "# from cargar_dataset import cargar_dataset\n",
    "\n",
    "# Lista de datasets a evaluar (claves presentes en tu config_datasets)\n",
    "lista_nombres_datasets = [\n",
    "    \"glass\",\n",
    "    \"ecoli\",\n",
    "    \"heart\",\n",
    "    \"wdbc\",\n",
    "    \"shuttle\",\n",
    "]\n",
    "\n",
    "# Hiperpar√°metros del detector de outliers\n",
    "parametros_isolation_forest = {\n",
    "    \"contamination\": 0.05,\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\": 100\n",
    "}\n",
    "\n",
    "# Umbral de significancia para normalidad por columna (p-valor)\n",
    "alfa_normalidad = 0.05\n",
    "\n",
    "# Para evitar que SHUTTLE u otros gigantes demoren, pod√©s muestrear:\n",
    "usar_muestreo = True\n",
    "tamano_muestra_maxima = 20000  # ajust√° seg√∫n tu m√°quina\n",
    "\n",
    "print(\"‚úÖ Integraci√≥n: listo para usar cargar_dataset(config_datasets).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ff7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# üß© Celda 3 ‚Äî Funciones (nombres expl√≠citos en espa√±ol)\n",
    "# ================================================\n",
    "def muestrear_si_corresponde(X, y, usar_muestreo, tamano_muestra_maxima, random_state=42):\n",
    "    if not usar_muestreo:\n",
    "        return X, y\n",
    "    cantidad = int(len(y))\n",
    "    if cantidad <= int(tamano_muestra_maxima):\n",
    "        return X, y\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    indices = np.arange(cantidad)\n",
    "    rng.shuffle(indices)\n",
    "    indices = indices[:int(tamano_muestra_maxima)]\n",
    "    X_m = X.iloc[indices].reset_index(drop=True)\n",
    "    y_m = y.iloc[indices].reset_index(drop=True)\n",
    "    return X_m, y_m\n",
    "\n",
    "def calcular_asimetria_promedio_absoluta(X):\n",
    "    columnas_numericas = []\n",
    "    for nombre_columna in X.columns:\n",
    "        if np.issubdtype(X[nombre_columna].dtype, np.number):\n",
    "            columnas_numericas.append(nombre_columna)\n",
    "\n",
    "    valores_asimetria = []\n",
    "    for nombre_columna in columnas_numericas:\n",
    "        serie = X[nombre_columna].astype(float)\n",
    "        valor_skew = skew(serie, bias=False, nan_policy='omit')\n",
    "        if isinstance(valor_skew, float) and not math.isnan(valor_skew):\n",
    "            valores_asimetria.append(abs(valor_skew))\n",
    "\n",
    "    if len(valores_asimetria) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    suma = 0.0\n",
    "    for v in valores_asimetria:\n",
    "        suma = suma + v\n",
    "    promedio = suma / float(len(valores_asimetria))\n",
    "    return promedio\n",
    "\n",
    "def calcular_porcentaje_columnas_normales(X, alfa):\n",
    "    columnas_numericas = []\n",
    "    for nombre_columna in X.columns:\n",
    "        if np.issubdtype(X[nombre_columna].dtype, np.number):\n",
    "            columnas_numericas.append(nombre_columna)\n",
    "\n",
    "    total = 0\n",
    "    normales = 0\n",
    "    for nombre_columna in columnas_numericas:\n",
    "        serie = X[nombre_columna].astype(float).dropna()\n",
    "        if serie.shape[0] >= 8:\n",
    "            try:\n",
    "                estadistico, pvalor = normaltest(serie)\n",
    "                total = total + 1\n",
    "                if pvalor > alfa:\n",
    "                    normales = normales + 1\n",
    "            except Exception:\n",
    "                # No sumo al total si falla\n",
    "                pass\n",
    "\n",
    "    if total == 0:\n",
    "        return float(\"nan\")\n",
    "    porcentaje = (normales / float(total)) * 100.0\n",
    "    return porcentaje\n",
    "\n",
    "def calcular_correlacion_maxima_absoluta(X):\n",
    "    Xn = X.select_dtypes(include=[np.number])\n",
    "    if Xn.shape[1] < 2:\n",
    "        return float(\"nan\")\n",
    "    matriz = Xn.corr(method=\"pearson\").abs()\n",
    "    # anular diagonal\n",
    "    filas = matriz.shape[0]\n",
    "    i = 0\n",
    "    while i < filas:\n",
    "        matriz.iat[i, i] = 0.0\n",
    "        i = i + 1\n",
    "    return float(matriz.values.max())\n",
    "\n",
    "def calcular_porcentaje_outliers_if(X, params):\n",
    "    Xn = X.select_dtypes(include=[np.number])\n",
    "    if Xn.shape[1] == 0:\n",
    "        return float(\"nan\")\n",
    "    modelo = IsolationForest(\n",
    "        contamination=params.get(\"contamination\", 0.05),\n",
    "        random_state=params.get(\"random_state\", 42),\n",
    "        n_estimators=params.get(\"n_estimators\", 100),\n",
    "        n_jobs=1\n",
    "    )\n",
    "    etiquetas = modelo.fit_predict(Xn)\n",
    "    total = int(len(etiquetas))\n",
    "    outl = 0\n",
    "    for e in etiquetas:\n",
    "        if int(e) == -1:\n",
    "            outl = outl + 1\n",
    "    porcentaje = (outl / float(total)) * 100.0\n",
    "    return porcentaje\n",
    "\n",
    "# ================================================\n",
    "# üîß Celda ‚Äî Utilidades de robustez de tipos\n",
    "# ================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def asegurar_dataframe_features_y(X, y, cfg):\n",
    "    \"\"\"\n",
    "    Si cargar_dataset devuelve arrays numpy, convierto a DataFrame/Series.\n",
    "    Usa cfg['col_features'] y cfg['col_target'] cuando est√°n disponibles.\n",
    "    \"\"\"\n",
    "    # X -> DataFrame\n",
    "    if isinstance(X, np.ndarray):\n",
    "        # nombres de columnas\n",
    "        if cfg.get(\"col_features\") is not None:\n",
    "            nombres_cols = list(cfg.get(\"col_features\"))\n",
    "        else:\n",
    "            # fallback expl√≠cito\n",
    "            ncols = int(X.shape[1])\n",
    "            nombres_cols = []\n",
    "            i = 0\n",
    "            while i < ncols:\n",
    "                nombres_cols.append(f\"feature_{i}\")\n",
    "                i = i + 1\n",
    "        X = pd.DataFrame(X, columns=nombres_cols)\n",
    "    # y -> Series\n",
    "    if isinstance(y, np.ndarray):\n",
    "        # nombre de target\n",
    "        nombre_target = cfg.get(\"col_target\", \"target\")\n",
    "        y = pd.Series(y, name=nombre_target)\n",
    "    return X, y\n",
    "\n",
    "def caracterizar_con_cargar_dataset(nombre_dataset, cfg, alfa, params, usar_muestreo, tamano_muestra_maxima):\n",
    "    X, y, _ = cargar_dataset(\n",
    "        path=cfg.get(\"path\"),\n",
    "        clase_minoria=cfg.get(\"clase_minoria\"),\n",
    "        col_features=cfg.get(\"col_features\"),\n",
    "        col_target=cfg.get(\"col_target\"),\n",
    "        sep=cfg.get(\"sep\", \",\"),\n",
    "        header=cfg.get(\"header\", None),\n",
    "        binarizar=cfg.get(\"binarizar\", False),\n",
    "        tipo=cfg.get(\"tipo\", \"tabular\"),\n",
    "        impute=cfg.get(\"impute\", \"median\"),\n",
    "        names=cfg.get(\"esquema\") if cfg.get(\"header\", None) is None else None,\n",
    "    )\n",
    "\n",
    "    # üëâ NUEVO: asegurar DataFrame/Series aunque cargar_dataset devuelva ndarrays\n",
    "    X, y = asegurar_dataframe_features_y(X, y, cfg)\n",
    "\n",
    "    # (resto de tu l√≥gica igual)\n",
    "    X, y = muestrear_si_corresponde(X, y, usar_muestreo, tamano_muestra_maxima)\n",
    "\n",
    "    n_muestras = int(X.shape[0])\n",
    "    n_features = int(X.shape[1])\n",
    "    n_clases = int(len(pd.unique(y)))\n",
    "\n",
    "    asim = calcular_asimetria_promedio_absoluta(X)\n",
    "    porc_norm = calcular_porcentaje_columnas_normales(X, alfa)\n",
    "    corr_max = calcular_correlacion_maxima_absoluta(X)\n",
    "    porc_outl = calcular_porcentaje_outliers_if(X, params)\n",
    "\n",
    "    if (not math.isnan(porc_outl) and porc_outl > 10.0) or (not math.isnan(porc_norm) and porc_norm < 30.0):\n",
    "        sugerencia = \"‚ö†Ô∏è Selectiva\"\n",
    "    elif not math.isnan(porc_outl) and porc_outl > 3.0:\n",
    "        sugerencia = \"üßπ Moderada\"\n",
    "    else:\n",
    "        sugerencia = \"‚ùå No\"\n",
    "\n",
    "    return {\n",
    "        \"Dataset\": nombre_dataset,\n",
    "        \"N (muestras)\": n_muestras,\n",
    "        \"# features\": n_features,\n",
    "        \"# clases\": n_clases,\n",
    "        \"% normalidad (K¬≤)\": None if math.isnan(porc_norm) else round(porc_norm, 1),\n",
    "        \"Asimetr√≠a promedio (|skew|)\": None if math.isnan(asim) else round(asim, 2),\n",
    "        \"Correlaci√≥n m√°x. (|r|)\": None if math.isnan(corr_max) else round(corr_max, 2),\n",
    "        \"% outliers (IF)\": None if math.isnan(porc_outl) else round(porc_outl, 1),\n",
    "        \"Limpieza recomendada\": sugerencia\n",
    "    }\n",
    "\n",
    "def generar_tabla_resumen_con_pipeline(config_datasets, lista_nombres, alfa, params, usar_muestreo, tamano_muestra_maxima):\n",
    "    resultados = []\n",
    "    for nombre in lista_nombres:\n",
    "        try:\n",
    "            cfg = config_datasets.get(nombre)\n",
    "            if cfg is None:\n",
    "                raise KeyError(f\"No existe config para '{nombre}' en config_datasets.\")\n",
    "            fila = caracterizar_con_cargar_dataset(\n",
    "                nombre_dataset=nombre,\n",
    "                cfg=cfg,\n",
    "                alfa=alfa,\n",
    "                params=params,\n",
    "                usar_muestreo=usar_muestreo,\n",
    "                tamano_muestra_maxima=tamano_muestra_maxima\n",
    "            )\n",
    "            resultados.append(fila)\n",
    "        except Exception as e:\n",
    "            resultados.append({\n",
    "                \"Dataset\": nombre,\n",
    "                \"N (muestras)\": None,\n",
    "                \"# features\": None,\n",
    "                \"# clases\": None,\n",
    "                \"% normalidad (K¬≤)\": None,\n",
    "                \"Asimetr√≠a promedio (|skew|)\": None,\n",
    "                \"Correlaci√≥n m√°x. (|r|)\": None,\n",
    "                \"% outliers (IF)\": None,\n",
    "                \"Limpieza recomendada\": f\"ERROR: {str(e)}\"\n",
    "            })\n",
    "    tabla = pd.DataFrame(resultados)\n",
    "    columnas = [\n",
    "        \"Dataset\",\n",
    "        \"N (muestras)\",\n",
    "        \"# features\",\n",
    "        \"# clases\",\n",
    "        \"% normalidad (K¬≤)\",\n",
    "        \"Asimetr√≠a promedio (|skew|)\",\n",
    "        \"Correlaci√≥n m√°x. (|r|)\",\n",
    "        \"% outliers (IF)\",\n",
    "        \"Limpieza recomendada\"\n",
    "    ]\n",
    "    tabla = tabla[columnas]\n",
    "    return tabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a588af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# üìè Celda ‚Äî Estudio Kolmogorov‚ÄìSmirnov (tabla aparte)\n",
    "# ================================================\n",
    "from scipy.stats import kstest\n",
    "\n",
    "def calcular_estadistica_ks_por_columnas(X):\n",
    "    \"\"\"\n",
    "    Para cada columna num√©rica:\n",
    "      1) z-score (resto media, divido por std; si std==0, omito esa columna)\n",
    "      2) kstest contra N(0,1)\n",
    "    Devuelve lista de dicts por columna con p-valor y estad√≠stico.\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    Xn = X.select_dtypes(include=[np.number])\n",
    "    for nombre_columna in Xn.columns:\n",
    "        serie = Xn[nombre_columna].astype(float).dropna()\n",
    "        if serie.shape[0] < 8:\n",
    "            continue\n",
    "        media = float(serie.mean())\n",
    "        desvio = float(serie.std(ddof=1))\n",
    "        if desvio == 0.0 or np.isnan(desvio):\n",
    "            continue\n",
    "        z = (serie - media) / desvio\n",
    "        # KS contra normal est√°ndar\n",
    "        estadistico, pvalor = kstest(z, \"norm\")\n",
    "        resultados.append({\n",
    "            \"columna\": nombre_columna,\n",
    "            \"n\": int(serie.shape[0]),\n",
    "            \"media\": media,\n",
    "            \"std\": desvio,\n",
    "            \"ks_stat\": float(estadistico),\n",
    "            \"pvalor\": float(pvalor)\n",
    "        })\n",
    "    return resultados\n",
    "\n",
    "def resumen_ks_dataset(nombre_dataset, resultados_columnas, alfa=0.05):\n",
    "    \"\"\"\n",
    "    Resume para un dataset: #cols evaluadas, #cols normales (p>alfa), %cols normales, p-min/mediana/max.\n",
    "    \"\"\"\n",
    "    total = int(len(resultados_columnas))\n",
    "    normales = 0\n",
    "    pvalores = []\n",
    "    i = 0\n",
    "    while i < total:\n",
    "        p = resultados_columnas[i][\"pvalor\"]\n",
    "        pvalores.append(p)\n",
    "        if p > alfa:\n",
    "            normales = normales + 1\n",
    "        i = i + 1\n",
    "\n",
    "    if total == 0:\n",
    "        return {\n",
    "            \"Dataset\": nombre_dataset,\n",
    "            \"# cols evaluadas (KS)\": 0,\n",
    "            \"# cols normales (KS)\": 0,\n",
    "            \"% cols normales (KS)\": \"\",\n",
    "            \"p-valor min\": \"\",\n",
    "            \"p-valor mediana\": \"\",\n",
    "            \"p-valor max\": \"\"\n",
    "        }\n",
    "\n",
    "    p_min = float(np.min(pvalores))\n",
    "    p_med = float(np.median(pvalores))\n",
    "    p_max = float(np.max(pvalores))\n",
    "\n",
    "    return {\n",
    "        \"Dataset\": nombre_dataset,\n",
    "        \"# cols evaluadas (KS)\": total,\n",
    "        \"# cols normales (KS)\": normales,\n",
    "        \"% cols normales (KS)\": round((normales / float(total)) * 100.0, 1),\n",
    "        \"p-valor min\": round(p_min, 4),\n",
    "        \"p-valor mediana\": round(p_med, 4),\n",
    "        \"p-valor max\": round(p_max, 4)\n",
    "    }\n",
    "\n",
    "def generar_tabla_ks(config_datasets, lista_nombres, alfa=0.05, usar_muestreo=False, tamano_muestra_maxima=50000):\n",
    "    \"\"\"\n",
    "    Genera:\n",
    "      - tabla resumen por dataset\n",
    "      - CSVs detallados por dataset (una fila por columna con ks_stat y p-valor)\n",
    "    \"\"\"\n",
    "    filas_resumen = []\n",
    "    carpeta_salida = \"../resultados/caracterizacion/ks\"\n",
    "    if not os.path.exists(carpeta_salida):\n",
    "        os.makedirs(carpeta_salida, exist_ok=True)\n",
    "\n",
    "    for nombre in lista_nombres:\n",
    "        try:\n",
    "            cfg = config_datasets.get(nombre)\n",
    "            if cfg is None:\n",
    "                raise KeyError(f\"No existe config para '{nombre}' en config_datasets.\")\n",
    "\n",
    "            X, y, _ = cargar_dataset(\n",
    "                path=cfg.get(\"path\"),\n",
    "                clase_minoria=cfg.get(\"clase_minoria\"),\n",
    "                col_features=cfg.get(\"col_features\"),\n",
    "                col_target=cfg.get(\"col_target\"),\n",
    "                sep=cfg.get(\"sep\", \",\"),\n",
    "                header=cfg.get(\"header\", None),\n",
    "                binarizar=cfg.get(\"binarizar\", False),\n",
    "                tipo=cfg.get(\"tipo\", \"tabular\"),\n",
    "                impute=cfg.get(\"impute\", \"median\"),\n",
    "                names=cfg.get(\"esquema\") if cfg.get(\"header\", None) is None else None,\n",
    "            )\n",
    "            # Asegurar DF/Series\n",
    "            X, y = asegurar_dataframe_features_y(X, y, cfg)\n",
    "\n",
    "            # Muestreo opcional\n",
    "            X, y = muestrear_si_corresponde(X, y, usar_muestreo, tamano_muestra_maxima)\n",
    "\n",
    "            # KS por columnas\n",
    "            resultados_cols = calcular_estadistica_ks_por_columnas(X)\n",
    "\n",
    "            # Guardar detalle por columnas\n",
    "            df_detalle = pd.DataFrame(resultados_cols)\n",
    "            ruta_detalle = os.path.join(carpeta_salida, f\"ks_detalle_{nombre}.csv\")\n",
    "            df_detalle.to_csv(ruta_detalle, index=False)\n",
    "\n",
    "            # Resumen por dataset\n",
    "            fila_resumen = resumen_ks_dataset(nombre, resultados_cols, alfa=alfa)\n",
    "            filas_resumen.append(fila_resumen)\n",
    "\n",
    "        except Exception as e:\n",
    "            filas_resumen.append({\n",
    "                \"Dataset\": nombre,\n",
    "                \"# cols evaluadas (KS)\": \"\",\n",
    "                \"# cols normales (KS)\": \"\",\n",
    "                \"% cols normales (KS)\": \"\",\n",
    "                \"p-valor min\": \"\",\n",
    "                \"p-valor mediana\": \"\",\n",
    "                \"p-valor max\": \"\",\n",
    "                \"ERROR\": str(e)\n",
    "            })\n",
    "\n",
    "    tabla_resumen_ks = pd.DataFrame(filas_resumen)\n",
    "    ruta_resumen = os.path.join(carpeta_salida, \"ks_resumen.csv\")\n",
    "    tabla_resumen_ks.to_csv(ruta_resumen, index=False)\n",
    "    return tabla_resumen_ks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d870ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Dataset   |   N (muestras) |   # features |   # clases |   % normalidad (K¬≤) |   Asimetr√≠a promedio (|skew|) |   Correlaci√≥n m√°x. (|r|) |   % outliers (IF) | Limpieza recomendada   |\n",
      "|:----------|---------------:|-------------:|-----------:|--------------------:|------------------------------:|-------------------------:|------------------:|:-----------------------|\n",
      "| glass     |            214 |            9 |          6 |                   0 |                          2.07 |                     0.81 |               5.1 | ‚ö†Ô∏è Selectiva           |\n",
      "| ecoli     |            336 |            7 |          8 |                   0 |                          3.65 |                     0.81 |               5.1 | ‚ö†Ô∏è Selectiva           |\n",
      "| heart     |            303 |           13 |          5 |                   0 |                          0.78 |                     0.58 |               5.3 | ‚ö†Ô∏è Selectiva           |\n",
      "| wdbc      |            569 |           30 |          2 |                   0 |                          1.74 |                     1    |               5.1 | ‚ö†Ô∏è Selectiva           |\n",
      "| shuttle   |          20000 |            9 |          7 |                   0 |                         18.09 |                     0.91 |               5   | ‚ö†Ô∏è Selectiva           |\n",
      "\n",
      "‚úÖ CSV: ../resultados/caracterizacion/resumen_caracterizacion.csv\n",
      "‚úÖ MD : ../resultados/caracterizacion/resumen_caracterizacion.md\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# üß© Celda 4 ‚Äî Ejecuci√≥n y guardado\n",
    "# ================================================\n",
    "tabla_resumen = generar_tabla_resumen_con_pipeline(\n",
    "    config_datasets=config_datasets,\n",
    "    lista_nombres=lista_nombres_datasets,\n",
    "    alfa=alfa_normalidad,\n",
    "    params=parametros_isolation_forest,\n",
    "    usar_muestreo=usar_muestreo,\n",
    "    tamano_muestra_maxima=tamano_muestra_maxima\n",
    ")\n",
    "\n",
    "# Mostrar\n",
    "print(tabla_resumen.to_markdown(index=False))\n",
    "\n",
    "# Guardar\n",
    "os.makedirs(\"../resultados/caracterizacion\", exist_ok=True)\n",
    "ruta_csv = \"../resultados/caracterizacion/resumen_caracterizacion.csv\"\n",
    "ruta_md  = \"../resultados/caracterizacion/resumen_caracterizacion.md\"\n",
    "\n",
    "tabla_resumen.to_csv(ruta_csv, index=False)\n",
    "\n",
    "with open(ruta_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    columnas = list(tabla_resumen.columns)\n",
    "    f.write(\"| \" + \" | \".join(columnas) + \" |\\n\")\n",
    "    alineacion = []\n",
    "    i = 0\n",
    "    while i < len(columnas):\n",
    "        if i == 0:\n",
    "            alineacion.append(\":---\")\n",
    "        else:\n",
    "            alineacion.append(\":---:\")\n",
    "        i = i + 1\n",
    "    f.write(\"|\" + \"|\".join(alineacion) + \"|\\n\")\n",
    "    for _, fila in tabla_resumen.iterrows():\n",
    "        valores = []\n",
    "        for c in columnas:\n",
    "            v = fila[c]\n",
    "            if v is None:\n",
    "                valores.append(\"\")\n",
    "            else:\n",
    "                valores.append(str(v))\n",
    "        f.write(\"| \" + \" | \".join(valores) + \" |\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ CSV: {ruta_csv}\")\n",
    "print(f\"‚úÖ MD : {ruta_md}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519b8879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Dataset   |   # cols evaluadas (KS) |   # cols normales (KS) |   % cols normales (KS) |   p-valor min |   p-valor mediana |   p-valor max |\n",
      "|:----------|------------------------:|-----------------------:|-----------------------:|--------------:|------------------:|--------------:|\n",
      "| glass     |                       9 |                      0 |                    0   |             0 |            0      |        0.042  |\n",
      "| ecoli     |                       7 |                      1 |                   14.3 |             0 |            0.0003 |        0.2114 |\n",
      "| heart     |                      13 |                      3 |                   23.1 |             0 |            0      |        0.2992 |\n",
      "| wdbc      |                      30 |                      5 |                   16.7 |             0 |            0      |        0.4608 |\n",
      "| shuttle   |                       9 |                      0 |                    0   |             0 |            0      |        0      |\n",
      "\n",
      "‚úÖ Guardado resumen KS en: ../resultados/caracterizacion/ks/ks_resumen.csv\n",
      "‚úÖ Guardado detalle por columnas en: ../resultados/caracterizacion/ks/ks_detalle_*.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ‚ñ∂Ô∏è Celda ‚Äî Ejecutar KS y guardar tablas\n",
    "# ================================================\n",
    "# Us√° la misma lista_nombres_datasets que ya ten√©s\n",
    "tabla_ks = generar_tabla_ks(\n",
    "    config_datasets=config_datasets,\n",
    "    lista_nombres=lista_nombres_datasets,\n",
    "    alfa=0.05,\n",
    "    usar_muestreo=True,             # para acelerar Shuttle si es grande\n",
    "    tamano_muestra_maxima=20000\n",
    ")\n",
    "\n",
    "print(tabla_ks.to_markdown(index=False))\n",
    "print(\"\\n‚úÖ Guardado resumen KS en: ../resultados/caracterizacion/ks/ks_resumen.csv\")\n",
    "print(\"‚úÖ Guardado detalle por columnas en: ../resultados/caracterizacion/ks/ks_detalle_*.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
