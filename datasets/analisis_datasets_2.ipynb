{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53ac8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Analizando dataset: US_CRIME\n",
      "üéØ Valores √∫nicos del target: [-1, 1]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - -1: 1844 (92.48%)\n",
      "   - 1: 150 (7.52%)\n",
      "   k=7  | consistencia=0.9128 | kNN_BAC=0.6243¬±0.0447 | kNN_F1m=0.6675¬±0.0565 | Jaccard=0.9100¬±0.1290 | margen=1.0099 (validos=413/1994)\n",
      "\n",
      "üîç Analizando dataset: SHUTTLE\n",
      "üéØ Valores √∫nicos del target: [1, 4, 5, 3, 2, 7, 6]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 1: 45586 (78.6%)\n",
      "   - 4: 8903 (15.35%)\n",
      "   - 5: 3267 (5.63%)\n",
      "   - 3: 171 (0.29%)\n",
      "   - 2: 50 (0.09%)\n",
      "   - 7: 13 (0.02%)\n",
      "   - 6: 10 (0.02%)\n",
      "   k=7  | consistencia=0.9972 | kNN_BAC=0.8601¬±0.0460 | kNN_F1m=0.8491¬±0.0396 | Jaccard=0.8837¬±0.1490 | margen=1.3491 (validos=381/58000)\n",
      "\n",
      "üîç Analizando dataset: WDBC\n",
      "üéØ Valores √∫nicos del target: ['B', 'M']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - B: 357 (62.74%)\n",
      "   - M: 212 (37.26%)\n",
      "   k=7  | consistencia=0.9066 | kNN_BAC=0.9169¬±0.0319 | kNN_F1m=0.9215¬±0.0250 | Jaccard=0.9982¬±0.0209 | margen=1.1008 (validos=126/569)\n",
      "\n",
      "üîç Analizando dataset: GLASS\n",
      "üéØ Valores √∫nicos del target: [2, 1, 7, 3, 5, 6]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 2: 76 (35.51%)\n",
      "   - 1: 70 (32.71%)\n",
      "   - 7: 29 (13.55%)\n",
      "   - 3: 17 (7.94%)\n",
      "   - 5: 13 (6.07%)\n",
      "   - 6: 9 (4.21%)\n",
      "   k=7  | consistencia=0.6055 | kNN_BAC=0.4732¬±0.0487 | kNN_F1m=0.4637¬±0.0651 | Jaccard=0.9335¬±0.1195 | margen=1.1636 (validos=153/214)\n",
      "\n",
      "üîç Analizando dataset: HEART\n",
      "üéØ Valores √∫nicos del target: [0, 1, 2, 3, 4]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 0: 164 (54.13%)\n",
      "   - 1: 55 (18.15%)\n",
      "   - 2: 36 (11.88%)\n",
      "   - 3: 35 (11.55%)\n",
      "   - 4: 13 (4.29%)\n",
      "   k=7  | consistencia=0.4064 | kNN_BAC=0.2159¬±0.0283 | kNN_F1m=0.1908¬±0.0373 | Jaccard=0.9967¬±0.0286 | margen=1.0130 (validos=238/303)\n",
      "\n",
      "üîç Analizando dataset: ECOLI\n",
      "üéØ Valores √∫nicos del target: ['cp', 'im', 'pp', 'imU', 'om', 'omL', 'imS', 'imL']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - cp: 143 (42.56%)\n",
      "   - im: 77 (22.92%)\n",
      "   - pp: 52 (15.48%)\n",
      "   - imU: 35 (10.42%)\n",
      "   - om: 20 (5.95%)\n",
      "   - omL: 5 (1.49%)\n",
      "   - imS: 2 (0.6%)\n",
      "   - imL: 2 (0.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=7  | consistencia=0.7925 | kNN_BAC=0.7642¬±0.0839 | kNN_F1m=0.7485¬±0.0928 | Jaccard=0.7562¬±0.1752 | margen=1.0610 (validos=165/336)\n",
      "\n",
      "üîç Analizando dataset: PREDICT_FAULTS\n",
      "üéØ Valores √∫nicos del target: ['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure', 'Random Failures']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - No Failure: 9652 (96.52%)\n",
      "   - Heat Dissipation Failure: 112 (1.12%)\n",
      "   - Power Failure: 95 (0.95%)\n",
      "   - Overstrain Failure: 78 (0.78%)\n",
      "   - Tool Wear Failure: 45 (0.45%)\n",
      "   - Random Failures: 18 (0.18%)\n",
      "   k=7  | consistencia=0.9520 | kNN_BAC=0.2506¬±0.0212 | kNN_F1m=0.2846¬±0.0269 | Jaccard=0.9940¬±0.0383 | margen=1.0316 (validos=1165/10000)\n",
      "\n",
      "üîç Analizando dataset: GEAR_VIBRATION\n",
      "üéØ Valores √∫nicos del target: ['no_fault', 'eccentricity', 'missing_tooth', 'root_crack', 'surface_fault', 'tooth_chipped_fault']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - no_fault: 30 (33.33%)\n",
      "   - eccentricity: 12 (13.33%)\n",
      "   - missing_tooth: 12 (13.33%)\n",
      "   - root_crack: 12 (13.33%)\n",
      "   - surface_fault: 12 (13.33%)\n",
      "   - tooth_chipped_fault: 12 (13.33%)\n",
      "   k=7  | consistencia=0.2746 | kNN_BAC=0.1278¬±0.0421 | kNN_F1m=0.0776¬±0.0234 | Jaccard=0.8401¬±0.1559 | margen=4.8602 (validos=82/90)\n",
      "\n",
      "üîç Analizando dataset: TELCO_CHURN\n",
      "üéØ Valores √∫nicos del target: ['no-churn', 'churn']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - no-churn: 5174 (73.46%)\n",
      "   - churn: 1869 (26.54%)\n",
      "   k=7  | consistencia=0.7127 | kNN_BAC=0.6691¬±0.0100 | kNN_F1m=0.6817¬±0.0108 | Jaccard=0.9906¬±0.0515 | margen=1.0595 (validos=4706/7043)\n",
      "\n",
      "üìÅ Reporte guardado en: resultados/reporte_distribucion_y_vecindad_2026-01-01_1002.txt\n",
      "üìÅ CSV guardado en: resultados/diagnostico_vecindad_2026-01-01_1002.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "\n",
    "from config_datasets import config_datasets\n",
    "from cargar_dataset import cargar_dataset, graficar_distribucion_clases\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# CONFIG\n",
    "# ======================================================================================\n",
    "K_VECINOS_LISTA = [7]\n",
    "N_SPLITS_CV = 5\n",
    "RANDOM_STATE = 42\n",
    "SIGMA_RUIDO = 0.01\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "Path(\"resultados\").mkdir(exist_ok=True)\n",
    "Path(\"figuras\").mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# M√âTRICAS (sin helpers \"m√°gicos\", todo expl√≠cito)\n",
    "# ======================================================================================\n",
    "def macro_f1(y_true, y_pred) -> float:\n",
    "    return float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "\n",
    "def balanced_acc(y_true, y_pred) -> float:\n",
    "    return float(balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 1: Consistencia vecinal (pureza de vecinos de misma clase)\n",
    "# ======================================================================================\n",
    "def estudio_consistencia_vecinal(X: np.ndarray, y: np.ndarray, k: int) -> dict:\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn.fit(X)\n",
    "    idx_vecinos = nn.kneighbors(X, return_distance=False)[:, 1:]  # quitamos el propio punto\n",
    "\n",
    "    consistencias = []\n",
    "    por_clase = {}\n",
    "\n",
    "    clases = np.unique(y)\n",
    "    for c in clases:\n",
    "        por_clase[c] = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        y_i = y[i]\n",
    "        vecinos = idx_vecinos[i]\n",
    "\n",
    "        misma = 0\n",
    "        for j in vecinos:\n",
    "            if y[j] == y_i:\n",
    "                misma += 1\n",
    "\n",
    "        c_i = misma / float(k)\n",
    "        consistencias.append(c_i)\n",
    "        por_clase[y_i].append(c_i)\n",
    "\n",
    "    media_global = float(np.mean(consistencias)) if len(consistencias) > 0 else 0.0\n",
    "\n",
    "    medias_clase = {}\n",
    "    for c in clases:\n",
    "        vals = por_clase[c]\n",
    "        medias_clase[c] = float(np.mean(vals)) if len(vals) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"consistencia_global_media\": media_global,\n",
    "        \"consistencia_media_por_clase\": medias_clase,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 2: kNN baseline (CV)\n",
    "# ======================================================================================\n",
    "def estudio_knn_baseline_cv(X: np.ndarray, y: np.ndarray, k: int, n_splits: int, random_state: int) -> dict:\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    bacs = []\n",
    "    f1s = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, metric=\"euclidean\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        bacs.append(balanced_acc(y_test, y_pred))\n",
    "        f1s.append(macro_f1(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"knn_bac_media\": float(np.mean(bacs)) if len(bacs) > 0 else 0.0,\n",
    "        \"knn_bac_std\": float(np.std(bacs, ddof=1)) if len(bacs) > 1 else 0.0,\n",
    "        \"knn_f1_macro_media\": float(np.mean(f1s)) if len(f1s) > 0 else 0.0,\n",
    "        \"knn_f1_macro_std\": float(np.std(f1s, ddof=1)) if len(f1s) > 1 else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 3: Estabilidad de vecindario (Jaccard A vs B)\n",
    "# B = X + ruido gaussiano leve\n",
    "# ======================================================================================\n",
    "def estudio_estabilidad_vecindario_jaccard(X: np.ndarray, k: int, sigma_ruido: float, random_state: int) -> dict:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    X_a = X\n",
    "    ruido = rng.normal(loc=0.0, scale=sigma_ruido, size=X.shape)\n",
    "    X_b = X + ruido\n",
    "\n",
    "    nn_a = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn_b = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn_a.fit(X_a)\n",
    "    nn_b.fit(X_b)\n",
    "\n",
    "    idx_a = nn_a.kneighbors(X_a, return_distance=False)[:, 1:]\n",
    "    idx_b = nn_b.kneighbors(X_b, return_distance=False)[:, 1:]\n",
    "\n",
    "    jaccards = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        set_a = set(idx_a[i].tolist())\n",
    "        set_b = set(idx_b[i].tolist())\n",
    "\n",
    "        inter = len(set_a.intersection(set_b))\n",
    "        uni = len(set_a.union(set_b))\n",
    "        j = inter / float(uni) if uni > 0 else 0.0\n",
    "        jaccards.append(j)\n",
    "\n",
    "    return {\n",
    "        \"jaccard_media\": float(np.mean(jaccards)) if len(jaccards) > 0 else 0.0,\n",
    "        \"jaccard_std\": float(np.std(jaccards, ddof=1)) if len(jaccards) > 1 else 0.0,\n",
    "        \"sigma_ruido\": sigma_ruido,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 4: Margen local (inter/intra)\n",
    "# ======================================================================================\n",
    "def estudio_margen_local(X: np.ndarray, y: np.ndarray, k: int, eps: float = 1e-9) -> dict:\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn.fit(X)\n",
    "    distancias, indices = nn.kneighbors(X, return_distance=True)\n",
    "\n",
    "    distancias = distancias[:, 1:]\n",
    "    indices = indices[:, 1:]\n",
    "\n",
    "    ratios = []\n",
    "    por_clase = {}\n",
    "\n",
    "    clases = np.unique(y)\n",
    "    for c in clases:\n",
    "        por_clase[c] = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        y_i = y[i]\n",
    "        idx_vec = indices[i]\n",
    "        dist_vec = distancias[i]\n",
    "\n",
    "        intra = []\n",
    "        inter = []\n",
    "\n",
    "        for pos in range(len(idx_vec)):\n",
    "            j = idx_vec[pos]\n",
    "            d = dist_vec[pos]\n",
    "            if y[j] == y_i:\n",
    "                intra.append(d)\n",
    "            else:\n",
    "                inter.append(d)\n",
    "\n",
    "        if len(intra) == 0 or len(inter) == 0:\n",
    "            continue\n",
    "\n",
    "        d_intra = float(np.mean(intra))\n",
    "        d_inter = float(np.mean(inter))\n",
    "        r_i = d_inter / (d_intra + eps)\n",
    "\n",
    "        ratios.append(r_i)\n",
    "        por_clase[y_i].append(r_i)\n",
    "\n",
    "    media_global = float(np.mean(ratios)) if len(ratios) > 0 else 0.0\n",
    "\n",
    "    medias_clase = {}\n",
    "    for c in clases:\n",
    "        vals = por_clase[c]\n",
    "        medias_clase[c] = float(np.mean(vals)) if len(vals) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"margen_local_media_global\": media_global,\n",
    "        \"margen_local_media_por_clase\": medias_clase,\n",
    "        \"n_validos\": int(len(ratios)),\n",
    "        \"n_total\": int(X.shape[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# MAIN\n",
    "# ======================================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "\n",
    "nombre_archivo_txt = f\"resultados/reporte_distribucion_y_vecindad_{timestamp}.txt\"\n",
    "nombre_archivo_csv = f\"resultados/diagnostico_vecindad_{timestamp}.csv\"\n",
    "\n",
    "lineas_resultado = []\n",
    "filas_csv = []\n",
    "\n",
    "for nombre, cfg in config_datasets.items():\n",
    "    lineas_resultado.append(f\"\\nüîç Analizando dataset: {nombre.upper()}\")\n",
    "    print(f\"\\nüîç Analizando dataset: {nombre.upper()}\")\n",
    "\n",
    "    try:\n",
    "        names = cfg.get(\"esquema\") if cfg.get(\"header\", None) is None else None\n",
    "\n",
    "        X, y, _ = cargar_dataset(\n",
    "            path=cfg.get(\"path\"),\n",
    "            clase_minoria=cfg.get(\"clase_minoria\"),\n",
    "            col_features=cfg.get(\"col_features\"),\n",
    "            col_target=cfg.get(\"col_target\"),\n",
    "            sep=cfg.get(\"sep\", \",\"),\n",
    "            header=cfg.get(\"header\", None),\n",
    "            binarizar=False,\n",
    "            tipo=cfg.get(\"tipo\", \"tabular\"),\n",
    "            impute=\"median\",\n",
    "            names=names\n",
    "        )\n",
    "        # Asegurar numpy para que el indexado por filas funcione siempre\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        else:\n",
    "            X = np.asarray(X)\n",
    "\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # -------------------------\n",
    "        # Distribuci√≥n de clases\n",
    "        # -------------------------\n",
    "        conteo = pd.Series(y).value_counts()\n",
    "        clase_min_real = conteo.idxmin()\n",
    "        total = conteo.sum()\n",
    "        proporcion = (conteo / total * 100).round(2)\n",
    "\n",
    "        print(\"üéØ Valores √∫nicos del target:\", list(conteo.index))\n",
    "        print(\"üìä Distribuci√≥n de clases:\")\n",
    "\n",
    "        lineas_resultado.append(f\"üéØ Valores √∫nicos del target: {list(conteo.index)}\")\n",
    "        lineas_resultado.append(\"üìä Distribuci√≥n de clases:\")\n",
    "\n",
    "        for clase, count in conteo.items():\n",
    "            print(f\"   - {clase}: {count} ({proporcion[clase]}%)\")\n",
    "            lineas_resultado.append(f\"   - {clase}: {count} ({proporcion[clase]}%)\")\n",
    "\n",
    "        lineas_resultado.append(f\"‚úÖ Clase minoritaria real: {clase_min_real}\")\n",
    "        lineas_resultado.append(f\"‚ö†Ô∏è Clase configurada como minoritaria: {cfg.get('clase_minoria')}\")\n",
    "\n",
    "        # Gr√°fico de distribuci√≥n\n",
    "        nombre_figura = f\"figuras/{nombre.lower()}_distribucion_{timestamp}.png\"\n",
    "        graficar_distribucion_clases(y, nombre_dataset=nombre, guardar_en=nombre_figura)\n",
    "\n",
    "        # -------------------------\n",
    "        # Diagn√≥stico de vecindad (4 estudios)\n",
    "        # -------------------------\n",
    "        lineas_resultado.append(\"üß≠ Diagn√≥stico de vecindad (m√©trica eucl√≠dea sobre X cargado):\")\n",
    "\n",
    "        for k in K_VECINOS_LISTA:\n",
    "            r1 = estudio_consistencia_vecinal(X, y, k)\n",
    "            r2 = estudio_knn_baseline_cv(X, y, k, N_SPLITS_CV, RANDOM_STATE)\n",
    "            r3 = estudio_estabilidad_vecindario_jaccard(X, k, SIGMA_RUIDO, RANDOM_STATE)\n",
    "            r4 = estudio_margen_local(X, y, k)\n",
    "\n",
    "            linea = (\n",
    "                f\"   k={k:<2} | \"\n",
    "                f\"consistencia={r1['consistencia_global_media']:.4f} | \"\n",
    "                f\"kNN_BAC={r2['knn_bac_media']:.4f}¬±{r2['knn_bac_std']:.4f} | \"\n",
    "                f\"kNN_F1m={r2['knn_f1_macro_media']:.4f}¬±{r2['knn_f1_macro_std']:.4f} | \"\n",
    "                f\"Jaccard={r3['jaccard_media']:.4f}¬±{r3['jaccard_std']:.4f} | \"\n",
    "                f\"margen={r4['margen_local_media_global']:.4f} (validos={r4['n_validos']}/{r4['n_total']})\"\n",
    "            )\n",
    "            print(linea)\n",
    "            lineas_resultado.append(linea)\n",
    "\n",
    "            filas_csv.append({\n",
    "                \"dataset\": nombre,\n",
    "                \"k\": k,\n",
    "                \"n_muestras\": int(X.shape[0]),\n",
    "                \"n_features\": int(X.shape[1]),\n",
    "\n",
    "                \"consistencia_vecinal_media\": float(r1[\"consistencia_global_media\"]),\n",
    "                \"knn_bac_media\": float(r2[\"knn_bac_media\"]),\n",
    "                \"knn_bac_std\": float(r2[\"knn_bac_std\"]),\n",
    "                \"knn_f1_macro_media\": float(r2[\"knn_f1_macro_media\"]),\n",
    "                \"knn_f1_macro_std\": float(r2[\"knn_f1_macro_std\"]),\n",
    "                \"jaccard_media\": float(r3[\"jaccard_media\"]),\n",
    "                \"jaccard_std\": float(r3[\"jaccard_std\"]),\n",
    "                \"margen_local_media\": float(r4[\"margen_local_media_global\"]),\n",
    "                \"margen_local_n_validos\": int(r4[\"n_validos\"]),\n",
    "                \"margen_local_n_total\": int(r4[\"n_total\"]),\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al analizar {nombre}: {e}\")\n",
    "        lineas_resultado.append(f\"‚ùå Error al analizar {nombre}: {e}\")\n",
    "\n",
    "# Guardar TXT\n",
    "with open(nombre_archivo_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lineas_resultado))\n",
    "\n",
    "# Guardar CSV\n",
    "df_out = pd.DataFrame(filas_csv)\n",
    "df_out.to_csv(nombre_archivo_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nüìÅ Reporte guardado en: {nombre_archivo_txt}\")\n",
    "print(f\"üìÅ CSV guardado en: {nombre_archivo_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda1dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Radares guardados en: D:\\Documentos_D\\etapa-analisis_pcsmote\\datasets\\figuras_radar\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "RUTA_CSV = \"resultados/diagnostico_vecindad_2026-01-01_1002.csv\"  \n",
    "K_ELEGIDO = 7\n",
    "SALIDA_DIR = Path(\"figuras_radar\")\n",
    "SALIDA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Normalizaci√≥n del margen:\n",
    "# - ratio ~1: malo (inter ~ intra)\n",
    "# - ratio >1: mejor separaci√≥n local\n",
    "# Cap expl√≠cito para meterlo en [0,1] sin distorsi√≥n.\n",
    "MARGEN_CAP = 5.0  # si quer√©s ser m√°s estricto: 2.0\n",
    "\n",
    "# -------------------------\n",
    "# CARGA + FILTRO\n",
    "# -------------------------\n",
    "df = pd.read_csv(RUTA_CSV)\n",
    "\n",
    "# Nos quedamos con un k fijo (recomendado) para que el radar sea comparable\n",
    "dfk = df[df[\"k\"] == K_ELEGIDO].copy()\n",
    "\n",
    "# Si hay datasets repetidos por cualquier raz√≥n, consolidamos por media\n",
    "agr = dfk.groupby(\"dataset\", as_index=False).agg({\n",
    "    \"knn_bac_media\": \"mean\",\n",
    "    \"knn_f1_macro_media\": \"mean\",\n",
    "    \"consistencia_vecinal_media\": \"mean\",\n",
    "    \"margen_local_media\": \"mean\"\n",
    "})\n",
    "\n",
    "# -------------------------\n",
    "# NORMALIZACI√ìN (sin jaccard)\n",
    "# -------------------------\n",
    "# BAC, F1m y consistencia ya est√°n en [0,1]\n",
    "# Margen: normalizaci√≥n anclada en 1 (punto neutro) y escalada por el m√°ximo observado\n",
    "\n",
    "# Valores v√°lidos de margen (positivos y no NaN)\n",
    "margenes_validos = []\n",
    "for v in agr[\"margen_local_media\"].tolist():\n",
    "    if pd.isna(v):\n",
    "        continue\n",
    "    if v > 0:\n",
    "        margenes_validos.append(float(v))\n",
    "\n",
    "if len(margenes_validos) == 0:\n",
    "    # Caso extremo: no hay m√°rgenes v√°lidos\n",
    "    agr[\"margen_norm\"] = 0.0\n",
    "else:\n",
    "    max_margen = max(margenes_validos)\n",
    "\n",
    "    # Si todos son ~1, evitamos divisi√≥n por 0\n",
    "    if max_margen <= 1.0:\n",
    "        agr[\"margen_norm\"] = 0.0\n",
    "    else:\n",
    "        margen_norm = []\n",
    "        for v in agr[\"margen_local_media\"].tolist():\n",
    "            if pd.isna(v) or v <= 0:\n",
    "                margen_norm.append(0.0)\n",
    "            else:\n",
    "                valor = (float(v) - 1.0) / (max_margen - 1.0)\n",
    "                if valor < 0:\n",
    "                    valor = 0.0\n",
    "                if valor > 1:\n",
    "                    valor = 1.0\n",
    "                margen_norm.append(valor)\n",
    "\n",
    "        agr[\"margen_norm\"] = margen_norm\n",
    "\n",
    "# -------------------------\n",
    "# RADAR POR DATASET (matplotlib puro)\n",
    "# -------------------------\n",
    "labels = [\"BAC\", \"F1m\", \"Consistencia\", \"Margen\"]\n",
    "n_vars = len(labels)\n",
    "\n",
    "# √°ngulos del radar\n",
    "angulos = np.linspace(0, 2*np.pi, n_vars, endpoint=False).tolist()\n",
    "angulos += angulos[:1]  # cerrar\n",
    "\n",
    "for i in range(agr.shape[0]):\n",
    "    nombre = str(agr.loc[i, \"dataset\"])\n",
    "\n",
    "    bac = float(agr.loc[i, \"knn_bac_media\"])\n",
    "    f1m = float(agr.loc[i, \"knn_f1_macro_media\"])\n",
    "    cons = float(agr.loc[i, \"consistencia_vecinal_media\"])\n",
    "    marg = float(agr.loc[i, \"margen_norm\"])\n",
    "\n",
    "    valores = [bac, f1m, cons, marg]\n",
    "    valores += valores[:1]  # cerrar\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    ax.set_xticks(angulos[:-1])\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
    "\n",
    "    ax.plot(angulos, valores, linewidth=2)\n",
    "    ax.fill(angulos, valores, alpha=0.15)\n",
    "\n",
    "    # t√≠tulo con info del cap para trazabilidad\n",
    "    ax.set_title(f\"{nombre} | k={K_ELEGIDO} | margen local ‚âà 1\", pad=20)\n",
    "\n",
    "    out = SALIDA_DIR / f\"radar_{nombre}_k{K_ELEGIDO}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Listo. Radares guardados en: {SALIDA_DIR.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
