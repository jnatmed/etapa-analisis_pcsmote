{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53ac8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Analizando dataset: US_CRIME\n",
      "üéØ Valores √∫nicos del target: [-1, 1]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - -1: 1844 (92.48%)\n",
      "   - 1: 150 (7.52%)\n",
      "   k=1  | consistencia=0.9208 | kNN_BAC=0.6473¬±0.0563 | kNN_F1m=0.6670¬±0.0621 | Jaccard=0.9273¬±0.2597 | margen=0.0000 (validos=0/1994)\n",
      "   k=3  | consistencia=0.9162 | kNN_BAC=0.6538¬±0.0440 | kNN_F1m=0.6909¬±0.0530 | Jaccard=0.9051¬±0.1973 | margen=1.0071 (validos=228/1994)\n",
      "   k=5  | consistencia=0.9142 | kNN_BAC=0.6304¬±0.0473 | kNN_F1m=0.6737¬±0.0608 | Jaccard=0.9042¬±0.1549 | margen=1.0110 (validos=336/1994)\n",
      "   k=7  | consistencia=0.9128 | kNN_BAC=0.6243¬±0.0447 | kNN_F1m=0.6675¬±0.0565 | Jaccard=0.9100¬±0.1290 | margen=1.0099 (validos=413/1994)\n",
      "\n",
      "üîç Analizando dataset: SHUTTLE\n",
      "üéØ Valores √∫nicos del target: [1, 4, 5, 3, 2, 7, 6]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 1: 45586 (78.6%)\n",
      "   - 4: 8903 (15.35%)\n",
      "   - 5: 3267 (5.63%)\n",
      "   - 3: 171 (0.29%)\n",
      "   - 2: 50 (0.09%)\n",
      "   - 7: 13 (0.02%)\n",
      "   - 6: 10 (0.02%)\n",
      "   k=1  | consistencia=0.9983 | kNN_BAC=0.9112¬±0.0165 | kNN_F1m=0.9057¬±0.0075 | Jaccard=0.7047¬±0.4562 | margen=0.0000 (validos=0/58000)\n",
      "   k=3  | consistencia=0.9979 | kNN_BAC=0.9084¬±0.0468 | kNN_F1m=0.9036¬±0.0479 | Jaccard=0.8487¬±0.2365 | margen=1.4330 (validos=180/58000)\n",
      "   k=5  | consistencia=0.9974 | kNN_BAC=0.9017¬±0.0559 | kNN_F1m=0.8782¬±0.0443 | Jaccard=0.8616¬±0.1829 | margen=1.4216 (validos=325/58000)\n",
      "   k=7  | consistencia=0.9972 | kNN_BAC=0.8601¬±0.0460 | kNN_F1m=0.8491¬±0.0396 | Jaccard=0.8837¬±0.1490 | margen=1.3491 (validos=381/58000)\n",
      "\n",
      "üîç Analizando dataset: WDBC\n",
      "üéØ Valores √∫nicos del target: ['B', 'M']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - B: 357 (62.74%)\n",
      "   - M: 212 (37.26%)\n",
      "   k=1  | consistencia=0.9156 | kNN_BAC=0.9056¬±0.0191 | kNN_F1m=0.9074¬±0.0152 | Jaccard=0.9982¬±0.0419 | margen=0.0000 (validos=0/569)\n",
      "   k=3  | consistencia=0.9174 | kNN_BAC=0.9198¬±0.0325 | kNN_F1m=0.9222¬±0.0288 | Jaccard=0.9991¬±0.0210 | margen=1.0397 (validos=65/569)\n",
      "   k=5  | consistencia=0.9114 | kNN_BAC=0.9263¬±0.0293 | kNN_F1m=0.9296¬±0.0245 | Jaccard=0.9982¬±0.0242 | margen=1.0731 (validos=102/569)\n",
      "   k=7  | consistencia=0.9066 | kNN_BAC=0.9169¬±0.0319 | kNN_F1m=0.9215¬±0.0250 | Jaccard=0.9982¬±0.0209 | margen=1.1008 (validos=126/569)\n",
      "\n",
      "üîç Analizando dataset: GLASS\n",
      "üéØ Valores √∫nicos del target: [2, 1, 7, 3, 5, 6]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 2: 76 (35.51%)\n",
      "   - 1: 70 (32.71%)\n",
      "   - 7: 29 (13.55%)\n",
      "   - 3: 17 (7.94%)\n",
      "   - 5: 13 (6.07%)\n",
      "   - 6: 9 (4.21%)\n",
      "   k=1  | consistencia=0.7336 | kNN_BAC=0.6948¬±0.0751 | kNN_F1m=0.6731¬±0.0743 | Jaccard=0.8972¬±0.3044 | margen=0.0000 (validos=0/214)\n",
      "   k=3  | consistencia=0.6729 | kNN_BAC=0.5839¬±0.1077 | kNN_F1m=0.5787¬±0.1008 | Jaccard=0.9047¬±0.2053 | margen=9160710.6169 (validos=79/214)\n",
      "   k=5  | consistencia=0.6299 | kNN_BAC=0.5067¬±0.0839 | kNN_F1m=0.5016¬±0.0987 | Jaccard=0.9261¬±0.1433 | margen=1.1640 (validos=131/214)\n",
      "   k=7  | consistencia=0.6055 | kNN_BAC=0.4732¬±0.0487 | kNN_F1m=0.4637¬±0.0651 | Jaccard=0.9335¬±0.1195 | margen=1.1636 (validos=153/214)\n",
      "\n",
      "üîç Analizando dataset: HEART\n",
      "üéØ Valores √∫nicos del target: [0, 1, 2, 3, 4]\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - 0: 164 (54.13%)\n",
      "   - 1: 55 (18.15%)\n",
      "   - 2: 36 (11.88%)\n",
      "   - 3: 35 (11.55%)\n",
      "   - 4: 13 (4.29%)\n",
      "   k=1  | consistencia=0.4191 | kNN_BAC=0.2414¬±0.0307 | kNN_F1m=0.2385¬±0.0320 | Jaccard=0.9967¬±0.0574 | margen=0.0000 (validos=0/303)\n",
      "   k=3  | consistencia=0.4037 | kNN_BAC=0.2045¬±0.0239 | kNN_F1m=0.1853¬±0.0393 | Jaccard=1.0000¬±0.0000 | margen=1.0328 (validos=160/303)\n",
      "   k=5  | consistencia=0.4020 | kNN_BAC=0.2051¬±0.0211 | kNN_F1m=0.1813¬±0.0283 | Jaccard=0.9956¬±0.0381 | margen=1.0223 (validos=206/303)\n",
      "   k=7  | consistencia=0.4064 | kNN_BAC=0.2159¬±0.0283 | kNN_F1m=0.1908¬±0.0373 | Jaccard=0.9967¬±0.0286 | margen=1.0130 (validos=238/303)\n",
      "\n",
      "üîç Analizando dataset: ECOLI\n",
      "üéØ Valores √∫nicos del target: ['cp', 'im', 'pp', 'imU', 'om', 'omL', 'imS', 'imL']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - cp: 143 (42.56%)\n",
      "   - im: 77 (22.92%)\n",
      "   - pp: 52 (15.48%)\n",
      "   - imU: 35 (10.42%)\n",
      "   - om: 20 (5.95%)\n",
      "   - omL: 5 (1.49%)\n",
      "   - imS: 2 (0.6%)\n",
      "   - imL: 2 (0.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1  | consistencia=0.8125 | kNN_BAC=0.7308¬±0.0964 | kNN_F1m=0.6681¬±0.1240 | Jaccard=0.6964¬±0.4605 | margen=0.0000 (validos=0/336)\n",
      "   k=3  | consistencia=0.8026 | kNN_BAC=0.7432¬±0.0914 | kNN_F1m=0.7135¬±0.1218 | Jaccard=0.7113¬±0.2812 | margen=1.0428 (validos=92/336)\n",
      "   k=5  | consistencia=0.7958 | kNN_BAC=0.7540¬±0.0859 | kNN_F1m=0.7365¬±0.0965 | Jaccard=0.7357¬±0.2114 | margen=1.0680 (validos=134/336)\n",
      "   k=7  | consistencia=0.7925 | kNN_BAC=0.7642¬±0.0839 | kNN_F1m=0.7485¬±0.0928 | Jaccard=0.7562¬±0.1752 | margen=1.0610 (validos=165/336)\n",
      "\n",
      "üîç Analizando dataset: PREDICT_FAULTS\n",
      "üéØ Valores √∫nicos del target: ['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure', 'Random Failures']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - No Failure: 9652 (96.52%)\n",
      "   - Heat Dissipation Failure: 112 (1.12%)\n",
      "   - Power Failure: 95 (0.95%)\n",
      "   - Overstrain Failure: 78 (0.78%)\n",
      "   - Tool Wear Failure: 45 (0.45%)\n",
      "   - Random Failures: 18 (0.18%)\n",
      "   k=1  | consistencia=0.9541 | kNN_BAC=0.3009¬±0.0288 | kNN_F1m=0.3187¬±0.0333 | Jaccard=0.9934¬±0.0810 | margen=0.0000 (validos=0/10000)\n",
      "   k=3  | consistencia=0.9529 | kNN_BAC=0.2646¬±0.0183 | kNN_F1m=0.2950¬±0.0202 | Jaccard=0.9932¬±0.0577 | margen=1.0682 (validos=618/10000)\n",
      "   k=5  | consistencia=0.9519 | kNN_BAC=0.2484¬±0.0333 | kNN_F1m=0.2789¬±0.0399 | Jaccard=0.9945¬±0.0426 | margen=1.0429 (validos=939/10000)\n",
      "   k=7  | consistencia=0.9520 | kNN_BAC=0.2506¬±0.0212 | kNN_F1m=0.2846¬±0.0269 | Jaccard=0.9940¬±0.0383 | margen=1.0316 (validos=1165/10000)\n",
      "\n",
      "üîç Analizando dataset: GEAR_VIBRATION\n",
      "üéØ Valores √∫nicos del target: ['no_fault', 'eccentricity', 'missing_tooth', 'root_crack', 'surface_fault', 'tooth_chipped_fault']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - no_fault: 30 (33.33%)\n",
      "   - eccentricity: 12 (13.33%)\n",
      "   - missing_tooth: 12 (13.33%)\n",
      "   - root_crack: 12 (13.33%)\n",
      "   - surface_fault: 12 (13.33%)\n",
      "   - tooth_chipped_fault: 12 (13.33%)\n",
      "   k=1  | consistencia=0.6444 | kNN_BAC=0.6167¬±0.1514 | kNN_F1m=0.5906¬±0.1378 | Jaccard=0.4778¬±0.5023 | margen=0.0000 (validos=0/90)\n",
      "   k=3  | consistencia=0.4370 | kNN_BAC=0.3333¬±0.1162 | kNN_F1m=0.3054¬±0.1052 | Jaccard=0.6489¬±0.3106 | margen=3.8699 (validos=63/90)\n",
      "   k=5  | consistencia=0.3444 | kNN_BAC=0.2111¬±0.1312 | kNN_F1m=0.1709¬±0.1195 | Jaccard=0.7902¬±0.2203 | margen=4.1463 (validos=82/90)\n",
      "   k=7  | consistencia=0.2746 | kNN_BAC=0.1278¬±0.0421 | kNN_F1m=0.0776¬±0.0234 | Jaccard=0.8401¬±0.1559 | margen=4.8602 (validos=82/90)\n",
      "\n",
      "üîç Analizando dataset: TELCO_CHURN\n",
      "üéØ Valores √∫nicos del target: ['no-churn', 'churn']\n",
      "üìä Distribuci√≥n de clases:\n",
      "   - no-churn: 5174 (73.46%)\n",
      "   - churn: 1869 (26.54%)\n",
      "   k=1  | consistencia=0.7163 | kNN_BAC=0.6380¬±0.0159 | kNN_F1m=0.6369¬±0.0152 | Jaccard=0.9837¬±0.1267 | margen=0.0000 (validos=0/7043)\n",
      "   k=3  | consistencia=0.7141 | kNN_BAC=0.6554¬±0.0092 | kNN_F1m=0.6627¬±0.0092 | Jaccard=0.9870¬±0.0829 | margen=137703.6756 (validos=3081/7043)\n",
      "   k=5  | consistencia=0.7136 | kNN_BAC=0.6636¬±0.0170 | kNN_F1m=0.6746¬±0.0183 | Jaccard=0.9893¬±0.0631 | margen=85939.9896 (validos=4114/7043)\n",
      "   k=7  | consistencia=0.7127 | kNN_BAC=0.6691¬±0.0100 | kNN_F1m=0.6817¬±0.0108 | Jaccard=0.9906¬±0.0515 | margen=1.0595 (validos=4706/7043)\n",
      "\n",
      "üìÅ Reporte guardado en: resultados/reporte_distribucion_y_vecindad_2025-12-29_1726.txt\n",
      "üìÅ CSV guardado en: resultados/diagnostico_vecindad_2025-12-29_1726.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "\n",
    "from config_datasets import config_datasets\n",
    "from cargar_dataset import cargar_dataset, graficar_distribucion_clases\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# CONFIG\n",
    "# ======================================================================================\n",
    "K_VECINOS_LISTA = [1, 3, 5, 7]\n",
    "N_SPLITS_CV = 5\n",
    "RANDOM_STATE = 42\n",
    "SIGMA_RUIDO = 0.01\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "Path(\"resultados\").mkdir(exist_ok=True)\n",
    "Path(\"figuras\").mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# M√âTRICAS (sin helpers \"m√°gicos\", todo expl√≠cito)\n",
    "# ======================================================================================\n",
    "def macro_f1(y_true, y_pred) -> float:\n",
    "    return float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "\n",
    "def balanced_acc(y_true, y_pred) -> float:\n",
    "    return float(balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 1: Consistencia vecinal (pureza de vecinos de misma clase)\n",
    "# ======================================================================================\n",
    "def estudio_consistencia_vecinal(X: np.ndarray, y: np.ndarray, k: int) -> dict:\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn.fit(X)\n",
    "    idx_vecinos = nn.kneighbors(X, return_distance=False)[:, 1:]  # quitamos el propio punto\n",
    "\n",
    "    consistencias = []\n",
    "    por_clase = {}\n",
    "\n",
    "    clases = np.unique(y)\n",
    "    for c in clases:\n",
    "        por_clase[c] = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        y_i = y[i]\n",
    "        vecinos = idx_vecinos[i]\n",
    "\n",
    "        misma = 0\n",
    "        for j in vecinos:\n",
    "            if y[j] == y_i:\n",
    "                misma += 1\n",
    "\n",
    "        c_i = misma / float(k)\n",
    "        consistencias.append(c_i)\n",
    "        por_clase[y_i].append(c_i)\n",
    "\n",
    "    media_global = float(np.mean(consistencias)) if len(consistencias) > 0 else 0.0\n",
    "\n",
    "    medias_clase = {}\n",
    "    for c in clases:\n",
    "        vals = por_clase[c]\n",
    "        medias_clase[c] = float(np.mean(vals)) if len(vals) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"consistencia_global_media\": media_global,\n",
    "        \"consistencia_media_por_clase\": medias_clase,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 2: kNN baseline (CV)\n",
    "# ======================================================================================\n",
    "def estudio_knn_baseline_cv(X: np.ndarray, y: np.ndarray, k: int, n_splits: int, random_state: int) -> dict:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    bacs = []\n",
    "    f1s = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_test = y[test_idx]\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, metric=\"euclidean\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        bacs.append(balanced_acc(y_test, y_pred))\n",
    "        f1s.append(macro_f1(y_test, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"knn_bac_media\": float(np.mean(bacs)) if len(bacs) > 0 else 0.0,\n",
    "        \"knn_bac_std\": float(np.std(bacs, ddof=1)) if len(bacs) > 1 else 0.0,\n",
    "        \"knn_f1_macro_media\": float(np.mean(f1s)) if len(f1s) > 0 else 0.0,\n",
    "        \"knn_f1_macro_std\": float(np.std(f1s, ddof=1)) if len(f1s) > 1 else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 3: Estabilidad de vecindario (Jaccard A vs B)\n",
    "# B = X + ruido gaussiano leve\n",
    "# ======================================================================================\n",
    "def estudio_estabilidad_vecindario_jaccard(X: np.ndarray, k: int, sigma_ruido: float, random_state: int) -> dict:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    X_a = X\n",
    "    ruido = rng.normal(loc=0.0, scale=sigma_ruido, size=X.shape)\n",
    "    X_b = X + ruido\n",
    "\n",
    "    nn_a = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn_b = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn_a.fit(X_a)\n",
    "    nn_b.fit(X_b)\n",
    "\n",
    "    idx_a = nn_a.kneighbors(X_a, return_distance=False)[:, 1:]\n",
    "    idx_b = nn_b.kneighbors(X_b, return_distance=False)[:, 1:]\n",
    "\n",
    "    jaccards = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        set_a = set(idx_a[i].tolist())\n",
    "        set_b = set(idx_b[i].tolist())\n",
    "\n",
    "        inter = len(set_a.intersection(set_b))\n",
    "        uni = len(set_a.union(set_b))\n",
    "        j = inter / float(uni) if uni > 0 else 0.0\n",
    "        jaccards.append(j)\n",
    "\n",
    "    return {\n",
    "        \"jaccard_media\": float(np.mean(jaccards)) if len(jaccards) > 0 else 0.0,\n",
    "        \"jaccard_std\": float(np.std(jaccards, ddof=1)) if len(jaccards) > 1 else 0.0,\n",
    "        \"sigma_ruido\": sigma_ruido,\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# ESTUDIO 4: Margen local (inter/intra)\n",
    "# ======================================================================================\n",
    "def estudio_margen_local(X: np.ndarray, y: np.ndarray, k: int, eps: float = 1e-9) -> dict:\n",
    "    nn = NearestNeighbors(n_neighbors=k + 1, metric=\"euclidean\")\n",
    "    nn.fit(X)\n",
    "    distancias, indices = nn.kneighbors(X, return_distance=True)\n",
    "\n",
    "    distancias = distancias[:, 1:]\n",
    "    indices = indices[:, 1:]\n",
    "\n",
    "    ratios = []\n",
    "    por_clase = {}\n",
    "\n",
    "    clases = np.unique(y)\n",
    "    for c in clases:\n",
    "        por_clase[c] = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        y_i = y[i]\n",
    "        idx_vec = indices[i]\n",
    "        dist_vec = distancias[i]\n",
    "\n",
    "        intra = []\n",
    "        inter = []\n",
    "\n",
    "        for pos in range(len(idx_vec)):\n",
    "            j = idx_vec[pos]\n",
    "            d = dist_vec[pos]\n",
    "            if y[j] == y_i:\n",
    "                intra.append(d)\n",
    "            else:\n",
    "                inter.append(d)\n",
    "\n",
    "        if len(intra) == 0 or len(inter) == 0:\n",
    "            continue\n",
    "\n",
    "        d_intra = float(np.mean(intra))\n",
    "        d_inter = float(np.mean(inter))\n",
    "        r_i = d_inter / (d_intra + eps)\n",
    "\n",
    "        ratios.append(r_i)\n",
    "        por_clase[y_i].append(r_i)\n",
    "\n",
    "    media_global = float(np.mean(ratios)) if len(ratios) > 0 else 0.0\n",
    "\n",
    "    medias_clase = {}\n",
    "    for c in clases:\n",
    "        vals = por_clase[c]\n",
    "        medias_clase[c] = float(np.mean(vals)) if len(vals) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"margen_local_media_global\": media_global,\n",
    "        \"margen_local_media_por_clase\": medias_clase,\n",
    "        \"n_validos\": int(len(ratios)),\n",
    "        \"n_total\": int(X.shape[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================================\n",
    "# MAIN\n",
    "# ======================================================================================\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "\n",
    "nombre_archivo_txt = f\"resultados/reporte_distribucion_y_vecindad_{timestamp}.txt\"\n",
    "nombre_archivo_csv = f\"resultados/diagnostico_vecindad_{timestamp}.csv\"\n",
    "\n",
    "lineas_resultado = []\n",
    "filas_csv = []\n",
    "\n",
    "for nombre, cfg in config_datasets.items():\n",
    "    lineas_resultado.append(f\"\\nüîç Analizando dataset: {nombre.upper()}\")\n",
    "    print(f\"\\nüîç Analizando dataset: {nombre.upper()}\")\n",
    "\n",
    "    try:\n",
    "        names = cfg.get(\"esquema\") if cfg.get(\"header\", None) is None else None\n",
    "\n",
    "        X, y, _ = cargar_dataset(\n",
    "            path=cfg.get(\"path\"),\n",
    "            clase_minoria=cfg.get(\"clase_minoria\"),\n",
    "            col_features=cfg.get(\"col_features\"),\n",
    "            col_target=cfg.get(\"col_target\"),\n",
    "            sep=cfg.get(\"sep\", \",\"),\n",
    "            header=cfg.get(\"header\", None),\n",
    "            binarizar=False,\n",
    "            tipo=cfg.get(\"tipo\", \"tabular\"),\n",
    "            impute=\"median\",\n",
    "            names=names\n",
    "        )\n",
    "        # Asegurar numpy para que el indexado por filas funcione siempre\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        else:\n",
    "            X = np.asarray(X)\n",
    "\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # -------------------------\n",
    "        # Distribuci√≥n de clases\n",
    "        # -------------------------\n",
    "        conteo = pd.Series(y).value_counts()\n",
    "        clase_min_real = conteo.idxmin()\n",
    "        total = conteo.sum()\n",
    "        proporcion = (conteo / total * 100).round(2)\n",
    "\n",
    "        print(\"üéØ Valores √∫nicos del target:\", list(conteo.index))\n",
    "        print(\"üìä Distribuci√≥n de clases:\")\n",
    "\n",
    "        lineas_resultado.append(f\"üéØ Valores √∫nicos del target: {list(conteo.index)}\")\n",
    "        lineas_resultado.append(\"üìä Distribuci√≥n de clases:\")\n",
    "\n",
    "        for clase, count in conteo.items():\n",
    "            print(f\"   - {clase}: {count} ({proporcion[clase]}%)\")\n",
    "            lineas_resultado.append(f\"   - {clase}: {count} ({proporcion[clase]}%)\")\n",
    "\n",
    "        lineas_resultado.append(f\"‚úÖ Clase minoritaria real: {clase_min_real}\")\n",
    "        lineas_resultado.append(f\"‚ö†Ô∏è Clase configurada como minoritaria: {cfg.get('clase_minoria')}\")\n",
    "\n",
    "        # Gr√°fico de distribuci√≥n\n",
    "        nombre_figura = f\"figuras/{nombre.lower()}_distribucion_{timestamp}.png\"\n",
    "        graficar_distribucion_clases(y, nombre_dataset=nombre, guardar_en=nombre_figura)\n",
    "\n",
    "        # -------------------------\n",
    "        # Diagn√≥stico de vecindad (4 estudios)\n",
    "        # -------------------------\n",
    "        lineas_resultado.append(\"üß≠ Diagn√≥stico de vecindad (m√©trica eucl√≠dea sobre X cargado):\")\n",
    "\n",
    "        for k in K_VECINOS_LISTA:\n",
    "            r1 = estudio_consistencia_vecinal(X, y, k)\n",
    "            r2 = estudio_knn_baseline_cv(X, y, k, N_SPLITS_CV, RANDOM_STATE)\n",
    "            r3 = estudio_estabilidad_vecindario_jaccard(X, k, SIGMA_RUIDO, RANDOM_STATE)\n",
    "            r4 = estudio_margen_local(X, y, k)\n",
    "\n",
    "            linea = (\n",
    "                f\"   k={k:<2} | \"\n",
    "                f\"consistencia={r1['consistencia_global_media']:.4f} | \"\n",
    "                f\"kNN_BAC={r2['knn_bac_media']:.4f}¬±{r2['knn_bac_std']:.4f} | \"\n",
    "                f\"kNN_F1m={r2['knn_f1_macro_media']:.4f}¬±{r2['knn_f1_macro_std']:.4f} | \"\n",
    "                f\"Jaccard={r3['jaccard_media']:.4f}¬±{r3['jaccard_std']:.4f} | \"\n",
    "                f\"margen={r4['margen_local_media_global']:.4f} (validos={r4['n_validos']}/{r4['n_total']})\"\n",
    "            )\n",
    "            print(linea)\n",
    "            lineas_resultado.append(linea)\n",
    "\n",
    "            filas_csv.append({\n",
    "                \"dataset\": nombre,\n",
    "                \"k\": k,\n",
    "                \"n_muestras\": int(X.shape[0]),\n",
    "                \"n_features\": int(X.shape[1]),\n",
    "\n",
    "                \"consistencia_vecinal_media\": float(r1[\"consistencia_global_media\"]),\n",
    "                \"knn_bac_media\": float(r2[\"knn_bac_media\"]),\n",
    "                \"knn_bac_std\": float(r2[\"knn_bac_std\"]),\n",
    "                \"knn_f1_macro_media\": float(r2[\"knn_f1_macro_media\"]),\n",
    "                \"knn_f1_macro_std\": float(r2[\"knn_f1_macro_std\"]),\n",
    "                \"jaccard_media\": float(r3[\"jaccard_media\"]),\n",
    "                \"jaccard_std\": float(r3[\"jaccard_std\"]),\n",
    "                \"margen_local_media\": float(r4[\"margen_local_media_global\"]),\n",
    "                \"margen_local_n_validos\": int(r4[\"n_validos\"]),\n",
    "                \"margen_local_n_total\": int(r4[\"n_total\"]),\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al analizar {nombre}: {e}\")\n",
    "        lineas_resultado.append(f\"‚ùå Error al analizar {nombre}: {e}\")\n",
    "\n",
    "# Guardar TXT\n",
    "with open(nombre_archivo_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lineas_resultado))\n",
    "\n",
    "# Guardar CSV\n",
    "df_out = pd.DataFrame(filas_csv)\n",
    "df_out.to_csv(nombre_archivo_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nüìÅ Reporte guardado en: {nombre_archivo_txt}\")\n",
    "print(f\"üìÅ CSV guardado en: {nombre_archivo_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
